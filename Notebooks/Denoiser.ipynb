{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a48HzTgzH5df",
      "metadata": {
        "id": "a48HzTgzH5df"
      },
      "source": [
        "## 1. Download dei dati ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9f56cb",
      "metadata": {
        "id": "be9f56cb"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "!wget https://www.zemris.fer.hr/projects/LicensePlates/english/baza_slika.zip\n",
        "# Unzip file zip\n",
        "!unzip -o -j baza_slika.zip \"*.jpg\" -d dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f687007c",
      "metadata": {
        "id": "f687007c"
      },
      "source": [
        "## 2. Preparazione dei dati ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "68ce22ff",
      "metadata": {
        "id": "68ce22ff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from skimage.transform import rescale\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "87d7819b",
      "metadata": {
        "id": "87d7819b"
      },
      "outputs": [],
      "source": [
        "# Percorso alla cartella che contiene le immagini\n",
        "datasetPath = \"dataset\"\n",
        "\n",
        "# Lista per salvare le immagini caricate\n",
        "imgList = []\n",
        "\n",
        "# Scorrimento di tutti i file nella cartella\n",
        "i = 0\n",
        "for fileName in os.listdir(datasetPath):\n",
        "    if fileName.lower().endswith(\".jpg\"):\n",
        "        filePath = os.path.join(datasetPath, fileName)\n",
        "        img = np.array(Image.open(filePath)).astype(np.float32) / 255.0\n",
        "        img = rescale(img, (1/1.66, 1/1.66, 1)) # Passaggio da 640x480 a 386x289\n",
        "        imgList.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eed425ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creazione rumore\n",
        "def addNoise(img):\n",
        "   \n",
        "    h,w,c = img.shape\n",
        "    d = random.randint(10, 25)/255\n",
        "    n = d*np.random.randn(h,w,c)\n",
        "    y = img+n\n",
        "    \n",
        "    if y.max() > 1.0:\n",
        "        y[y > 1.0] = 1.0\n",
        "    if y.min() < 0.0:\n",
        "        y[y < 0.0] = 0.0\n",
        "    \n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd875f2",
      "metadata": {
        "id": "0bd875f2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "# Modifica del dataset\n",
        "class ImgListDataset(Dataset):\n",
        "    def __init__(self, imgList):\n",
        "        self.imgList = imgList\n",
        "        self.target_size = (289, 386)           # Altezza e larghezza desiderata\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),            # Conversione a immagine\n",
        "            transforms.Resize(self.target_size),\n",
        "            transforms.ToTensor()               # Conversione a tensore\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgList)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgList[idx]\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = self.transform(img)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22cf6d4e",
      "metadata": {
        "id": "22cf6d4e"
      },
      "outputs": [],
      "source": [
        "# Divisione dell'intero dataset in training set, validation set e test set (80%, 10% e 10%)\n",
        "trainSet, valSet, testSet = random_split(imgList, [0.8, 0.1, 0.1])\n",
        "\n",
        "# Creazione dei dataset di immagini rumorose\n",
        "trainSetNoise = []\n",
        "valSetNoise = []\n",
        "testSetNoise = []\n",
        "\n",
        "for el in trainSet:\n",
        "    imgNoise = addNoise(el)\n",
        "    trainSetNoise.append(imgNoise)\n",
        "\n",
        "for el in valSet:\n",
        "    imgNoise = addNoise(el)\n",
        "    valSetNoise.append(imgNoise)\n",
        "\n",
        "for el in testSet:\n",
        "    imgNoise = addNoise(el)\n",
        "    testSetNoise.append(imgNoise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af2e0e1",
      "metadata": {
        "id": "2af2e0e1",
        "outputId": "2980e7fd-3485-4ce0-8b9f-13fe4b5d246c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Effettuata suddivisione:\n",
            "- Training-set: 403 campioni.\n",
            "- Validation-set: 50 campioni.\n",
            "- Test-set: 50 campioni.\n",
            "- Training-set Noise: 403 campioni.\n",
            "- Validation-set Noise: 50 campioni.\n",
            "- Test-set Noise: 50 campioni.\n"
          ]
        }
      ],
      "source": [
        "# Definizione variabili\n",
        "batchSize = 6\n",
        "numWorkers = 4\n",
        "\n",
        "# Modifica del dataset per le immagini originali\n",
        "trainSetDataset = ImgListDataset(trainSet)\n",
        "valSetDataset = ImgListDataset(valSet)\n",
        "testSetDataset = ImgListDataset(testSet)\n",
        "\n",
        "# Dataloader per le immagini originali\n",
        "trainDataload = DataLoader(trainSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "valDataload = DataLoader(valSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "testDataload = DataLoader(testSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "\n",
        "# Modifica del dataset per le immagini rumorose\n",
        "trainSetRicDataset = ImgListDataset(trainSetNoise)\n",
        "valSetRicDataset = ImgListDataset(valSetNoise)\n",
        "testSetRicDataset = ImgListDataset(testSetNoise)\n",
        "\n",
        "# Dataloader per le immagini rumorose\n",
        "trainDataloadNoise = DataLoader(trainSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "valDataloadNoise = DataLoader(valSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "testDataloadNoise = DataLoader(testSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "\n",
        "print(\"Effettuata suddivisione:\")\n",
        "print(f\"- Training-set: {len(trainSet)} campioni.\")\n",
        "print(f\"- Validation-set: {len(valSet)} campioni.\")\n",
        "print(f\"- Test-set: {len(testSet)} campioni.\")\n",
        "print(f\"- Training-set Noise: {len(trainSetNoise)} campioni.\")\n",
        "print(f\"- Validation-set Noise: {len(valSetNoise)} campioni.\")\n",
        "print(f\"- Test-set Noise: {len(testSetNoise)} campioni.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b895ccf1",
      "metadata": {
        "id": "b895ccf1"
      },
      "source": [
        "## 3. Architettura ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440f2cea",
      "metadata": {
        "id": "440f2cea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=64, kernel_size=3, padding=1):\n",
        "        super(DnCNN, self).__init__()\n",
        "        # in_channel = 3 poichÃ¨ 3 canali\n",
        "        # out_channel = 64 come scritto nella traccia (num feat)\n",
        "        # kernel_size = 3 come scritto nella traccia (dim spaziale 3x3)\n",
        "        \n",
        "        layers = []\n",
        "\n",
        "        # Iter 1: Convolution + ReLU\n",
        "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        # Iters 2-16: Convolution + BatchNorm + ReLU\n",
        "        for i in range(15):\n",
        "            layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))                    # Corrisponde al numero di canali di output del livello precedente\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        # Iters 17: Convolution\n",
        "        layers.append(nn.Conv2d(in_channels=out_channels, out_channels=in_channels, kernel_size=kernel_size, padding=padding))\n",
        "\n",
        "        # *layers corrisponde a layers[0],layers[1],..., quindi giÃ  spalmati come singoli elementi\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        self.apply(self.kernel_initializer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "    # Equivalente a kernel_inizializer=\"Orthogonal\" in pytorch\n",
        "    def kernel_initializer(self, module):\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            nn.init.orthogonal_(module.weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76be591b",
      "metadata": {
        "id": "76be591b"
      },
      "source": [
        "## 4. Addestramento ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d154678e",
      "metadata": {
        "id": "d154678e"
      },
      "outputs": [],
      "source": [
        "# Importiamo le librerie necessarie\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c4f5aa",
      "metadata": {
        "id": "52c4f5aa",
        "outputId": "c71eaa96-2f86-43aa-917a-fa1a8e56e753"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Abilitazione del dispositivo GPU per il training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770ddf07",
      "metadata": {
        "id": "770ddf07"
      },
      "outputs": [],
      "source": [
        "# Legenda dataloader:\n",
        "#   - dlTrain = immagini originali training\n",
        "#   - dlTrainNoise = immagini rumorose training\n",
        "#   - dlVal = immagini originali validation\n",
        "#   - dlValNoise = immagini rumorose validation\n",
        "def training (dlTrain, dlTrainNoise, dlVal, dlValNoise, numEpoch, model, criterion, optimizer, bestMse, bestPsnr, outputPath):\n",
        "\n",
        "    # Liste dei risultati definite per un'ipotetica visualizzazione\n",
        "    MSETrainList = []\n",
        "    MSEValList = []\n",
        "    PSNRTrainList = []\n",
        "    PSNRValList = []\n",
        "\n",
        "    # Iterazione per ogni epoch\n",
        "    for epoch in range(numEpoch):\n",
        "\n",
        "        model.cuda()\n",
        "        # Conteggio del tempo per misurare la durata di un'epoca\n",
        "        since = time.time()\n",
        "\n",
        "        # Inizializzazione delle variabili\n",
        "        modelMseTrain = 0.0\n",
        "        totalSize = 0\n",
        "\n",
        "        # Modello impostato in traning mode\n",
        "        model.train()\n",
        "\n",
        "        # Iterazione per ogni batch\n",
        "        # Devo iterare su i 2 dataloader contemporaneamente, per fare ciÃ² utilizzo zip\n",
        "        for (inputsTrain, inputsNoise) in zip(dlTrain, dlTrainNoise):\n",
        "\n",
        "            # Converto gli input in tensori float e li carico nella GPU\n",
        "            inputsTrain = inputsTrain.type(torch.FloatTensor).cuda()\n",
        "            inputsNoise = inputsNoise.type(torch.FloatTensor).cuda()\n",
        "\n",
        "            # Reset dei gradienti, altrimenti i vecchi gradienti sono sommati ai nuovi, piuttosto\n",
        "            # che essere sovrascritti\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Calcolo dettagli\n",
        "            yTrain = model(inputsNoise)\n",
        "            y = inputsNoise - yTrain\n",
        "\n",
        "            # Calcolo della MSE\n",
        "            loss = criterion(y, inputsTrain)\n",
        "            # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "            # media per il numero di elementi per ottenere la somma totale della loss\n",
        "            modelMseTrain += loss.item() * inputsTrain.size(0)\n",
        "            totalSize += inputsTrain.size(0)\n",
        "\n",
        "            # Calcolando il gradiente del tensore attuale\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()        # Aggiornamento dei parametri\n",
        "            optimizer.zero_grad()   # Azzeramento dei gradienti per il prossimo ciclo di accumulo\n",
        "            \n",
        "\n",
        "        # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "        modelMseEpochTrain = modelMseTrain/totalSize\n",
        "        modelPsnrEpochTrain = 10 * torch.log10(torch.tensor(1/modelMseEpochTrain))\n",
        "\n",
        "        # Salvataggio dei pesi per ogni iterazione (disabilitato)\n",
        "        # torch.save(model.state_dict(), outputPath + \"train_weights.pth\")\n",
        "\n",
        "        # Modello impostato in validation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Inizializzazione delle variabili\n",
        "        modelMseVal = 0.0\n",
        "        totalSizeVal = 0\n",
        "\n",
        "        with torch.no_grad():               # Disattiva il calcolo dei gradienti\n",
        "        # Iterazione per ogni bach\n",
        "        # Devo iterare su i 2 dataloader contemporaneamente, per fare ciÃ² utilizzo zip\n",
        "            for (inputsVal, inputsValNoise) in zip(dlVal, dlValNoise):\n",
        "\n",
        "                # Converto gli input in tensori float e li carico nella GPU\n",
        "                inputsVal = inputsVal.type(torch.FloatTensor).cuda()\n",
        "                inputsValNoise = inputsValNoise.type(torch.FloatTensor).cuda()\n",
        "\n",
        "                # Calcolo dettagli\n",
        "                yVal = model(inputsValNoise)\n",
        "                y = inputsValNoise - yVal \n",
        "\n",
        "                # Calcolo della MSE\n",
        "                loss = criterion(y, inputsVal)\n",
        "                # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "                # media per il numero di elementi per ottenere la somma totale della loss\n",
        "                modelMseVal += loss.item() * inputsVal.size(0)\n",
        "                totalSizeVal += inputsVal.size(0)\n",
        "\n",
        "            # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "            modelMseEpochVal = modelMseVal/totalSizeVal\n",
        "            modelPsnrEpochVal = 10 * torch.log10(torch.tensor(1/modelMseEpochVal))\n",
        "            timeElapsed = time.time()-since\n",
        "\n",
        "        print('[Epoch %d][Train on %d [MSE: %.4f  PSNR: %.4f]][Val on %d [MSE: %.4f  PSNR: %.4f]][Time: %.0f m %.0f s]'\n",
        "                %(epoch, totalSize, modelMseEpochTrain, modelPsnrEpochTrain, totalSizeVal, modelMseEpochVal,\n",
        "                modelPsnrEpochVal, timeElapsed // 60, timeElapsed % 60))\n",
        "\n",
        "        # Salvaggio dei risultati migliori\n",
        "        if (modelMseEpochVal < bestMse):\n",
        "            print(\"-------Saving best weights-------\")\n",
        "            bestMse = modelMseEpochVal\n",
        "            bestPsnr = modelPsnrEpochVal\n",
        "            # Salvataggio dei migliori risultati\n",
        "            try:\n",
        "                torch.save(model.cpu().state_dict(), outputPath)\n",
        "                print(\"-------Best weights saved-------\")\n",
        "            except Exception as e:\n",
        "                print(\"Error:\", e)\n",
        "\n",
        "        # Salvataggio dei risultati per la visualizzazione\n",
        "        MSETrainList.append(modelMseEpochTrain)\n",
        "        MSEValList.append(modelMseEpochVal)\n",
        "        PSNRTrainList.append(modelPsnrEpochTrain)\n",
        "        PSNRValList.append(modelPsnrEpochVal)\n",
        "\n",
        "    return bestMse, bestPsnr, MSETrainList, MSEValList, PSNRTrainList, PSNRValList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13e3c40",
      "metadata": {
        "id": "c13e3c40"
      },
      "outputs": [],
      "source": [
        "# Funzione di testing\n",
        "\n",
        "def testing (dlTest, dlTestNoise, model, criterion, weightPath):\n",
        "\n",
        "    # Caricamento dei pesi\n",
        "    model.load_state_dict(torch.load(weightPath, map_location=torch.device(\"cpu\")))\n",
        "    model.cuda()\n",
        "\n",
        "    # Conteggio del tempo per misurare la durata di un'epoca\n",
        "    since = time.time()\n",
        "\n",
        "    # Inizializzazione delle variabili\n",
        "    modelMseTest = 0.0\n",
        "    totalSize = 0\n",
        "    outputsTest = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Iterazione su batch\n",
        "    with torch.no_grad():               # Disattiva il calcolo dei gradienti\n",
        "        for (inputsTest, inputsTestNoise) in zip(dlTest, dlTestNoise):\n",
        "\n",
        "\n",
        "            # Converto gli input in tensori float e li carico nella GPU\n",
        "            inputsTest = inputsTest.type(torch.FloatTensor).cuda()\n",
        "            inputsTestNoise = inputsTestNoise.type(torch.FloatTensor).cuda()\n",
        "\n",
        "            # Calcolo dettagli e ricostruzione immagine\n",
        "            yTest = model(inputsTestNoise)\n",
        "            y = inputsTestNoise - yTest\n",
        "            outputsTest.append(y)\n",
        "\n",
        "            # Calcolo della MSE\n",
        "            loss = criterion(y, inputsTest)\n",
        "            # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "            # media per il numero di elementi per ottenere la somma totale della loss\n",
        "            modelMseTest += loss.item() * inputsTest.size(0)\n",
        "            totalSize += inputsTest.size(0)\n",
        "\n",
        "\n",
        "        # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "        modelMseEpochTest = modelMseTest/totalSize\n",
        "        modelPsnrEpochTest = 10 * torch.log10(torch.tensor(1/modelMseEpochTest))\n",
        "        timeElapsed = time.time()-since\n",
        "\n",
        "        print(\"[Test] [MSE: %.4f  PSNR: %.4f] [Time: %.0f m %.0f s]\"\n",
        "          %(modelMseEpochTest, modelPsnrEpochTest, timeElapsed // 60, timeElapsed % 60))\n",
        "\n",
        "        return outputsTest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6fc029",
      "metadata": {
        "id": "ca6fc029"
      },
      "source": [
        "## 5. Valutazione delle prestazioni ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5cd243",
      "metadata": {
        "id": "6b5cd243"
      },
      "outputs": [],
      "source": [
        "# Iper-parametri\n",
        "epochList = [60]\n",
        "learningRateList = [0.01, 0.001, 0.0001]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25666195",
      "metadata": {
        "id": "25666195"
      },
      "outputs": [],
      "source": [
        "# Main\n",
        "import torch.optim as optim\n",
        "\n",
        "model = DnCNN().cuda()\n",
        "criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "bestMSEComb = 9000000000000000000.0              # Miglior MSE tra tutte le combinazioni\n",
        "bestPSNRComb = -900000000000000000.0             # Miglior PSNR tra tutte le combinazioni\n",
        "\n",
        "# Definizione dei percorsi per il salvataggio dei pesi\n",
        "weightPath = \"best_weights_denoise.pth\"         \n",
        "weightPathComb = \"best_weights_denoise_lr.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfc263c",
      "metadata": {
        "id": "8dfc263c",
        "outputId": "3e36426b-4069-4919-d0a2-e62a2930b6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0][Train on 403 [MSE: 0.3390  PSNR: 4.6974]][Val on 50 [MSE: 0.0058  PSNR: 22.3552]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0049  PSNR: 23.1114]][Val on 50 [MSE: 0.0047  PSNR: 23.3177]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0045  PSNR: 23.4211]][Val on 50 [MSE: 0.0046  PSNR: 23.3946]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0045  PSNR: 23.4744]][Val on 50 [MSE: 0.0045  PSNR: 23.4606]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0045  PSNR: 23.4989]][Val on 50 [MSE: 0.0045  PSNR: 23.4647]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0045  PSNR: 23.5132]][Val on 50 [MSE: 0.0045  PSNR: 23.4774]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0044  PSNR: 23.5232]][Val on 50 [MSE: 0.0045  PSNR: 23.4937]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0044  PSNR: 23.5325]][Val on 50 [MSE: 0.0045  PSNR: 23.4974]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0044  PSNR: 23.5387]][Val on 50 [MSE: 0.0045  PSNR: 23.4996]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0044  PSNR: 23.5439]][Val on 50 [MSE: 0.0045  PSNR: 23.4785]][Time: 0 m 49 s]\n",
            "[Epoch 10][Train on 403 [MSE: 0.0044  PSNR: 23.5463]][Val on 50 [MSE: 0.0045  PSNR: 23.5039]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0044  PSNR: 23.5514]][Val on 50 [MSE: 0.0045  PSNR: 23.5099]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0044  PSNR: 23.5512]][Val on 50 [MSE: 0.0044  PSNR: 23.5287]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0044  PSNR: 23.5588]][Val on 50 [MSE: 0.0044  PSNR: 23.5453]][Time: 0 m 49 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 14][Train on 403 [MSE: 0.0044  PSNR: 23.5664]][Val on 50 [MSE: 0.0044  PSNR: 23.5325]][Time: 0 m 49 s]\n",
            "[Epoch 15][Train on 403 [MSE: 0.0044  PSNR: 23.5700]][Val on 50 [MSE: 0.0044  PSNR: 23.5302]][Time: 0 m 50 s]\n",
            "[Epoch 16][Train on 403 [MSE: 0.0044  PSNR: 23.5718]][Val on 50 [MSE: 0.0044  PSNR: 23.5244]][Time: 0 m 49 s]\n",
            "[Epoch 17][Train on 403 [MSE: 0.0044  PSNR: 23.5731]][Val on 50 [MSE: 0.0045  PSNR: 23.5041]][Time: 0 m 49 s]\n",
            "[Epoch 18][Train on 403 [MSE: 0.0044  PSNR: 23.5731]][Val on 50 [MSE: 0.0045  PSNR: 23.4867]][Time: 0 m 49 s]\n",
            "[Epoch 19][Train on 403 [MSE: 0.0044  PSNR: 23.5724]][Val on 50 [MSE: 0.0045  PSNR: 23.4804]][Time: 0 m 49 s]\n",
            "[Epoch 20][Train on 403 [MSE: 0.0044  PSNR: 23.5718]][Val on 50 [MSE: 0.0045  PSNR: 23.4552]][Time: 0 m 49 s]\n",
            "[Epoch 21][Train on 403 [MSE: 0.0044  PSNR: 23.5721]][Val on 50 [MSE: 0.0045  PSNR: 23.4917]][Time: 0 m 49 s]\n",
            "[Epoch 22][Train on 403 [MSE: 0.0044  PSNR: 23.5749]][Val on 50 [MSE: 0.0045  PSNR: 23.4871]][Time: 0 m 50 s]\n",
            "[Epoch 23][Train on 403 [MSE: 0.0044  PSNR: 23.5761]][Val on 50 [MSE: 0.0045  PSNR: 23.5047]][Time: 0 m 52 s]\n",
            "[Epoch 24][Train on 403 [MSE: 0.0044  PSNR: 23.5769]][Val on 50 [MSE: 0.0045  PSNR: 23.4849]][Time: 0 m 51 s]\n",
            "[Epoch 25][Train on 403 [MSE: 0.0044  PSNR: 23.5763]][Val on 50 [MSE: 0.0045  PSNR: 23.4977]][Time: 0 m 52 s]\n",
            "[Epoch 26][Train on 403 [MSE: 0.0044  PSNR: 23.5771]][Val on 50 [MSE: 0.0045  PSNR: 23.4736]][Time: 0 m 51 s]\n",
            "[Epoch 27][Train on 403 [MSE: 0.0044  PSNR: 23.5761]][Val on 50 [MSE: 0.0045  PSNR: 23.4912]][Time: 0 m 52 s]\n",
            "[Epoch 28][Train on 403 [MSE: 0.0044  PSNR: 23.5763]][Val on 50 [MSE: 0.0045  PSNR: 23.4574]][Time: 0 m 51 s]\n",
            "[Epoch 29][Train on 403 [MSE: 0.0044  PSNR: 23.5766]][Val on 50 [MSE: 0.0045  PSNR: 23.4800]][Time: 0 m 51 s]\n",
            "[Epoch 30][Train on 403 [MSE: 0.0044  PSNR: 23.5771]][Val on 50 [MSE: 0.0045  PSNR: 23.4850]][Time: 0 m 51 s]\n",
            "[Epoch 31][Train on 403 [MSE: 0.0044  PSNR: 23.5781]][Val on 50 [MSE: 0.0044  PSNR: 23.5291]][Time: 0 m 52 s]\n",
            "[Epoch 32][Train on 403 [MSE: 0.0044  PSNR: 23.5766]][Val on 50 [MSE: 0.0045  PSNR: 23.5063]][Time: 0 m 51 s]\n",
            "[Epoch 33][Train on 403 [MSE: 0.0044  PSNR: 23.5764]][Val on 50 [MSE: 0.0045  PSNR: 23.5041]][Time: 0 m 51 s]\n",
            "[Epoch 34][Train on 403 [MSE: 0.0044  PSNR: 23.5745]][Val on 50 [MSE: 0.0044  PSNR: 23.5474]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 35][Train on 403 [MSE: 0.0044  PSNR: 23.5670]][Val on 50 [MSE: 0.0044  PSNR: 23.5181]][Time: 0 m 51 s]\n",
            "[Epoch 36][Train on 403 [MSE: 0.0044  PSNR: 23.5723]][Val on 50 [MSE: 0.0044  PSNR: 23.5434]][Time: 0 m 51 s]\n",
            "[Epoch 37][Train on 403 [MSE: 0.0044  PSNR: 23.5719]][Val on 50 [MSE: 0.0044  PSNR: 23.5383]][Time: 0 m 51 s]\n",
            "[Epoch 38][Train on 403 [MSE: 0.0044  PSNR: 23.5543]][Val on 50 [MSE: 0.0045  PSNR: 23.5044]][Time: 0 m 51 s]\n",
            "[Epoch 39][Train on 403 [MSE: 0.0044  PSNR: 23.5366]][Val on 50 [MSE: 0.0044  PSNR: 23.5165]][Time: 0 m 51 s]\n",
            "[Epoch 40][Train on 403 [MSE: 0.0044  PSNR: 23.5561]][Val on 50 [MSE: 0.0044  PSNR: 23.5398]][Time: 0 m 51 s]\n",
            "[Epoch 41][Train on 403 [MSE: 0.0044  PSNR: 23.5602]][Val on 50 [MSE: 0.0044  PSNR: 23.5409]][Time: 0 m 51 s]\n",
            "[Epoch 42][Train on 403 [MSE: 0.0045  PSNR: 23.5157]][Val on 50 [MSE: 0.0045  PSNR: 23.5090]][Time: 0 m 51 s]\n",
            "[Epoch 43][Train on 403 [MSE: 0.0044  PSNR: 23.5298]][Val on 50 [MSE: 0.0044  PSNR: 23.5330]][Time: 0 m 51 s]\n",
            "[Epoch 44][Train on 403 [MSE: 0.0044  PSNR: 23.5423]][Val on 50 [MSE: 0.0063  PSNR: 22.0326]][Time: 0 m 51 s]\n",
            "[Epoch 45][Train on 403 [MSE: 0.0045  PSNR: 23.5075]][Val on 50 [MSE: 0.0045  PSNR: 23.4696]][Time: 0 m 51 s]\n",
            "[Epoch 46][Train on 403 [MSE: 0.0044  PSNR: 23.5630]][Val on 50 [MSE: 0.0049  PSNR: 23.1312]][Time: 0 m 51 s]\n",
            "[Epoch 47][Train on 403 [MSE: 0.0045  PSNR: 23.4818]][Val on 50 [MSE: 0.0044  PSNR: 23.5349]][Time: 0 m 51 s]\n",
            "[Epoch 48][Train on 403 [MSE: 0.0044  PSNR: 23.5584]][Val on 50 [MSE: 0.0046  PSNR: 23.4146]][Time: 0 m 51 s]\n",
            "[Epoch 49][Train on 403 [MSE: 0.0044  PSNR: 23.5275]][Val on 50 [MSE: 0.0044  PSNR: 23.5361]][Time: 0 m 52 s]\n",
            "[Epoch 50][Train on 403 [MSE: 0.0045  PSNR: 23.4655]][Val on 50 [MSE: 0.0045  PSNR: 23.5004]][Time: 0 m 51 s]\n",
            "[Epoch 51][Train on 403 [MSE: 0.0044  PSNR: 23.5785]][Val on 50 [MSE: 0.0044  PSNR: 23.5268]][Time: 0 m 51 s]\n",
            "[Epoch 52][Train on 403 [MSE: 0.0044  PSNR: 23.5211]][Val on 50 [MSE: 0.0044  PSNR: 23.5347]][Time: 0 m 51 s]\n",
            "[Epoch 53][Train on 403 [MSE: 0.0045  PSNR: 23.5080]][Val on 50 [MSE: 0.0048  PSNR: 23.1734]][Time: 0 m 51 s]\n",
            "[Epoch 54][Train on 403 [MSE: 0.0044  PSNR: 23.5495]][Val on 50 [MSE: 0.0045  PSNR: 23.4631]][Time: 0 m 51 s]\n",
            "[Epoch 55][Train on 403 [MSE: 0.0044  PSNR: 23.5667]][Val on 50 [MSE: 0.0045  PSNR: 23.5119]][Time: 0 m 51 s]\n",
            "[Epoch 56][Train on 403 [MSE: 0.0045  PSNR: 23.4513]][Val on 50 [MSE: 0.0044  PSNR: 23.5465]][Time: 0 m 51 s]\n",
            "[Epoch 57][Train on 403 [MSE: 0.0044  PSNR: 23.5567]][Val on 50 [MSE: 0.0044  PSNR: 23.5175]][Time: 0 m 51 s]\n",
            "[Epoch 58][Train on 403 [MSE: 0.0044  PSNR: 23.5748]][Val on 50 [MSE: 0.0045  PSNR: 23.5048]][Time: 0 m 52 s]\n",
            "[Epoch 59][Train on 403 [MSE: 0.0044  PSNR: 23.5938]][Val on 50 [MSE: 0.0044  PSNR: 23.5478]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "------Best Combination saved [Epoch: 60 - Learning Rate: 0.01]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0045  PSNR: 23.4551]][Val on 50 [MSE: 0.0043  PSNR: 23.6304]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0043  PSNR: 23.7007]][Val on 50 [MSE: 0.0043  PSNR: 23.6496]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0042  PSNR: 23.7875]][Val on 50 [MSE: 0.0041  PSNR: 23.8260]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0040  PSNR: 23.9906]][Val on 50 [MSE: 0.0039  PSNR: 24.0569]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0038  PSNR: 24.2201]][Val on 50 [MSE: 0.0037  PSNR: 24.2654]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0035  PSNR: 24.5359]][Val on 50 [MSE: 0.0034  PSNR: 24.7009]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0033  PSNR: 24.7597]][Val on 50 [MSE: 0.0033  PSNR: 24.7876]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0033  PSNR: 24.8287]][Val on 50 [MSE: 0.0033  PSNR: 24.8767]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0032  PSNR: 24.9159]][Val on 50 [MSE: 0.0032  PSNR: 24.9579]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0032  PSNR: 24.9702]][Val on 50 [MSE: 0.0032  PSNR: 24.9379]][Time: 0 m 52 s]\n",
            "[Epoch 10][Train on 403 [MSE: 0.0032  PSNR: 25.0143]][Val on 50 [MSE: 0.0032  PSNR: 24.9190]][Time: 0 m 51 s]\n",
            "[Epoch 11][Train on 403 [MSE: 0.0031  PSNR: 25.0489]][Val on 50 [MSE: 0.0031  PSNR: 25.0610]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0031  PSNR: 25.0822]][Val on 50 [MSE: 0.0031  PSNR: 25.0741]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0031  PSNR: 25.1069]][Val on 50 [MSE: 0.0031  PSNR: 25.0607]][Time: 0 m 51 s]\n",
            "[Epoch 14][Train on 403 [MSE: 0.0031  PSNR: 25.1155]][Val on 50 [MSE: 0.0031  PSNR: 25.1252]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 15][Train on 403 [MSE: 0.0031  PSNR: 25.1505]][Val on 50 [MSE: 0.0031  PSNR: 25.1273]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0030  PSNR: 25.1898]][Val on 50 [MSE: 0.0030  PSNR: 25.1647]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0030  PSNR: 25.2424]][Val on 50 [MSE: 0.0030  PSNR: 25.1744]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0029  PSNR: 25.3872]][Val on 50 [MSE: 0.0030  PSNR: 25.2394]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0027  PSNR: 25.6696]][Val on 50 [MSE: 0.0026  PSNR: 25.8461]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 20][Train on 403 [MSE: 0.0025  PSNR: 26.0525]][Val on 50 [MSE: 0.0024  PSNR: 26.2309]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 21][Train on 403 [MSE: 0.0022  PSNR: 26.5192]][Val on 50 [MSE: 0.0021  PSNR: 26.7313]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 22][Train on 403 [MSE: 0.0020  PSNR: 26.9457]][Val on 50 [MSE: 0.0020  PSNR: 27.0631]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 23][Train on 403 [MSE: 0.0020  PSNR: 27.0860]][Val on 50 [MSE: 0.0020  PSNR: 27.0397]][Time: 0 m 51 s]\n",
            "[Epoch 24][Train on 403 [MSE: 0.0019  PSNR: 27.1584]][Val on 50 [MSE: 0.0019  PSNR: 27.1169]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 25][Train on 403 [MSE: 0.0019  PSNR: 27.1967]][Val on 50 [MSE: 0.0019  PSNR: 27.1816]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 26][Train on 403 [MSE: 0.0019  PSNR: 27.2133]][Val on 50 [MSE: 0.0019  PSNR: 27.2695]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 27][Train on 403 [MSE: 0.0019  PSNR: 27.2498]][Val on 50 [MSE: 0.0018  PSNR: 27.3641]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 28][Train on 403 [MSE: 0.0019  PSNR: 27.2487]][Val on 50 [MSE: 0.0018  PSNR: 27.4590]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 29][Train on 403 [MSE: 0.0018  PSNR: 27.3628]][Val on 50 [MSE: 0.0018  PSNR: 27.4644]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 30][Train on 403 [MSE: 0.0018  PSNR: 27.3753]][Val on 50 [MSE: 0.0018  PSNR: 27.4161]][Time: 0 m 54 s]\n",
            "[Epoch 31][Train on 403 [MSE: 0.0018  PSNR: 27.4394]][Val on 50 [MSE: 0.0018  PSNR: 27.5469]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 32][Train on 403 [MSE: 0.0018  PSNR: 27.4996]][Val on 50 [MSE: 0.0017  PSNR: 27.6173]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 33][Train on 403 [MSE: 0.0018  PSNR: 27.4573]][Val on 50 [MSE: 0.0018  PSNR: 27.5552]][Time: 0 m 55 s]\n",
            "[Epoch 34][Train on 403 [MSE: 0.0018  PSNR: 27.5044]][Val on 50 [MSE: 0.0017  PSNR: 27.5962]][Time: 0 m 54 s]\n",
            "[Epoch 35][Train on 403 [MSE: 0.0018  PSNR: 27.5502]][Val on 50 [MSE: 0.0018  PSNR: 27.5659]][Time: 0 m 54 s]\n",
            "[Epoch 36][Train on 403 [MSE: 0.0017  PSNR: 27.5735]][Val on 50 [MSE: 0.0017  PSNR: 27.5917]][Time: 0 m 54 s]\n",
            "[Epoch 37][Train on 403 [MSE: 0.0017  PSNR: 27.6183]][Val on 50 [MSE: 0.0017  PSNR: 27.6233]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 38][Train on 403 [MSE: 0.0017  PSNR: 27.6176]][Val on 50 [MSE: 0.0017  PSNR: 27.6875]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 39][Train on 403 [MSE: 0.0017  PSNR: 27.6488]][Val on 50 [MSE: 0.0021  PSNR: 26.8467]][Time: 0 m 54 s]\n",
            "[Epoch 40][Train on 403 [MSE: 0.0018  PSNR: 27.4673]][Val on 50 [MSE: 0.0017  PSNR: 27.6369]][Time: 0 m 54 s]\n",
            "[Epoch 41][Train on 403 [MSE: 0.0017  PSNR: 27.5863]][Val on 50 [MSE: 0.0017  PSNR: 27.7286]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 42][Train on 403 [MSE: 0.0017  PSNR: 27.6749]][Val on 50 [MSE: 0.0017  PSNR: 27.7373]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 43][Train on 403 [MSE: 0.0017  PSNR: 27.7314]][Val on 50 [MSE: 0.0016  PSNR: 27.8589]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 44][Train on 403 [MSE: 0.0017  PSNR: 27.8205]][Val on 50 [MSE: 0.0016  PSNR: 27.9548]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 45][Train on 403 [MSE: 0.0016  PSNR: 27.9362]][Val on 50 [MSE: 0.0016  PSNR: 28.0701]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 46][Train on 403 [MSE: 0.0015  PSNR: 28.1717]][Val on 50 [MSE: 0.0015  PSNR: 28.3381]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 47][Train on 403 [MSE: 0.0014  PSNR: 28.4767]][Val on 50 [MSE: 0.0013  PSNR: 28.8170]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 48][Train on 403 [MSE: 0.0013  PSNR: 28.9507]][Val on 50 [MSE: 0.0012  PSNR: 29.2308]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 49][Train on 403 [MSE: 0.0011  PSNR: 29.6706]][Val on 50 [MSE: 0.0009  PSNR: 30.3009]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 50][Train on 403 [MSE: 0.0009  PSNR: 30.4391]][Val on 50 [MSE: 0.0007  PSNR: 31.3216]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 51][Train on 403 [MSE: 0.0008  PSNR: 31.1355]][Val on 50 [MSE: 0.0007  PSNR: 31.7289]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 52][Train on 403 [MSE: 0.0007  PSNR: 31.5644]][Val on 50 [MSE: 0.0006  PSNR: 31.9310]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 53][Train on 403 [MSE: 0.0007  PSNR: 31.4764]][Val on 50 [MSE: 0.0007  PSNR: 31.8539]][Time: 0 m 53 s]\n",
            "[Epoch 54][Train on 403 [MSE: 0.0007  PSNR: 31.3184]][Val on 50 [MSE: 0.0007  PSNR: 31.4025]][Time: 0 m 54 s]\n",
            "[Epoch 55][Train on 403 [MSE: 0.0007  PSNR: 31.3121]][Val on 50 [MSE: 0.0006  PSNR: 32.0588]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 56][Train on 403 [MSE: 0.0007  PSNR: 31.7064]][Val on 50 [MSE: 0.0006  PSNR: 32.2686]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 57][Train on 403 [MSE: 0.0007  PSNR: 31.7132]][Val on 50 [MSE: 0.0006  PSNR: 31.8794]][Time: 0 m 54 s]\n",
            "[Epoch 58][Train on 403 [MSE: 0.0007  PSNR: 31.7263]][Val on 50 [MSE: 0.0007  PSNR: 31.6948]][Time: 0 m 54 s]\n",
            "[Epoch 59][Train on 403 [MSE: 0.0007  PSNR: 31.8177]][Val on 50 [MSE: 0.0006  PSNR: 32.1823]][Time: 0 m 54 s]\n",
            "------Best Combination saved [Epoch: 60 - Learning Rate: 0.001]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0006  PSNR: 32.1438]][Val on 50 [MSE: 0.0006  PSNR: 32.4483]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0006  PSNR: 32.2764]][Val on 50 [MSE: 0.0006  PSNR: 32.5082]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0006  PSNR: 32.3154]][Val on 50 [MSE: 0.0006  PSNR: 32.5387]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0006  PSNR: 32.3455]][Val on 50 [MSE: 0.0006  PSNR: 32.5582]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0006  PSNR: 32.3720]][Val on 50 [MSE: 0.0006  PSNR: 32.5736]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0006  PSNR: 32.3955]][Val on 50 [MSE: 0.0006  PSNR: 32.5878]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0006  PSNR: 32.4175]][Val on 50 [MSE: 0.0005  PSNR: 32.5985]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0006  PSNR: 32.4383]][Val on 50 [MSE: 0.0005  PSNR: 32.6103]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0006  PSNR: 32.4584]][Val on 50 [MSE: 0.0005  PSNR: 32.6200]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0006  PSNR: 32.4773]][Val on 50 [MSE: 0.0005  PSNR: 32.6279]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 10][Train on 403 [MSE: 0.0006  PSNR: 32.4954]][Val on 50 [MSE: 0.0005  PSNR: 32.6367]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0006  PSNR: 32.5132]][Val on 50 [MSE: 0.0005  PSNR: 32.6460]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0006  PSNR: 32.5299]][Val on 50 [MSE: 0.0005  PSNR: 32.6530]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0006  PSNR: 32.5464]][Val on 50 [MSE: 0.0005  PSNR: 32.6595]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 14][Train on 403 [MSE: 0.0006  PSNR: 32.5626]][Val on 50 [MSE: 0.0005  PSNR: 32.6656]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 15][Train on 403 [MSE: 0.0006  PSNR: 32.5786]][Val on 50 [MSE: 0.0005  PSNR: 32.6707]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0006  PSNR: 32.5934]][Val on 50 [MSE: 0.0005  PSNR: 32.6752]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0005  PSNR: 32.6076]][Val on 50 [MSE: 0.0005  PSNR: 32.6800]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0005  PSNR: 32.6212]][Val on 50 [MSE: 0.0005  PSNR: 32.6848]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0005  PSNR: 32.6346]][Val on 50 [MSE: 0.0005  PSNR: 32.6885]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 20][Train on 403 [MSE: 0.0005  PSNR: 32.6478]][Val on 50 [MSE: 0.0005  PSNR: 32.6922]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 21][Train on 403 [MSE: 0.0005  PSNR: 32.6599]][Val on 50 [MSE: 0.0005  PSNR: 32.6960]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 22][Train on 403 [MSE: 0.0005  PSNR: 32.6727]][Val on 50 [MSE: 0.0005  PSNR: 32.6997]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 23][Train on 403 [MSE: 0.0005  PSNR: 32.6838]][Val on 50 [MSE: 0.0005  PSNR: 32.7018]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 24][Train on 403 [MSE: 0.0005  PSNR: 32.6955]][Val on 50 [MSE: 0.0005  PSNR: 32.7045]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 25][Train on 403 [MSE: 0.0005  PSNR: 32.7066]][Val on 50 [MSE: 0.0005  PSNR: 32.7068]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 26][Train on 403 [MSE: 0.0005  PSNR: 32.7176]][Val on 50 [MSE: 0.0005  PSNR: 32.7096]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 27][Train on 403 [MSE: 0.0005  PSNR: 32.7279]][Val on 50 [MSE: 0.0005  PSNR: 32.7116]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 28][Train on 403 [MSE: 0.0005  PSNR: 32.7380]][Val on 50 [MSE: 0.0005  PSNR: 32.7154]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 29][Train on 403 [MSE: 0.0005  PSNR: 32.7481]][Val on 50 [MSE: 0.0005  PSNR: 32.7184]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 30][Train on 403 [MSE: 0.0005  PSNR: 32.7580]][Val on 50 [MSE: 0.0005  PSNR: 32.7201]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 31][Train on 403 [MSE: 0.0005  PSNR: 32.7673]][Val on 50 [MSE: 0.0005  PSNR: 32.7202]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 32][Train on 403 [MSE: 0.0005  PSNR: 32.7765]][Val on 50 [MSE: 0.0005  PSNR: 32.7212]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 33][Train on 403 [MSE: 0.0005  PSNR: 32.7854]][Val on 50 [MSE: 0.0005  PSNR: 32.7239]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 34][Train on 403 [MSE: 0.0005  PSNR: 32.7938]][Val on 50 [MSE: 0.0005  PSNR: 32.7275]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 35][Train on 403 [MSE: 0.0005  PSNR: 32.8017]][Val on 50 [MSE: 0.0005  PSNR: 32.7298]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 36][Train on 403 [MSE: 0.0005  PSNR: 32.8097]][Val on 50 [MSE: 0.0005  PSNR: 32.7330]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 37][Train on 403 [MSE: 0.0005  PSNR: 32.8174]][Val on 50 [MSE: 0.0005  PSNR: 32.7346]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 38][Train on 403 [MSE: 0.0005  PSNR: 32.8244]][Val on 50 [MSE: 0.0005  PSNR: 32.7386]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 39][Train on 403 [MSE: 0.0005  PSNR: 32.8314]][Val on 50 [MSE: 0.0005  PSNR: 32.7447]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 40][Train on 403 [MSE: 0.0005  PSNR: 32.8362]][Val on 50 [MSE: 0.0005  PSNR: 32.7473]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 41][Train on 403 [MSE: 0.0005  PSNR: 32.8387]][Val on 50 [MSE: 0.0005  PSNR: 32.7517]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 42][Train on 403 [MSE: 0.0005  PSNR: 32.8380]][Val on 50 [MSE: 0.0005  PSNR: 32.7426]][Time: 0 m 53 s]\n",
            "[Epoch 43][Train on 403 [MSE: 0.0005  PSNR: 32.8313]][Val on 50 [MSE: 0.0005  PSNR: 32.7340]][Time: 0 m 53 s]\n",
            "[Epoch 44][Train on 403 [MSE: 0.0005  PSNR: 32.8172]][Val on 50 [MSE: 0.0005  PSNR: 32.7452]][Time: 0 m 53 s]\n",
            "[Epoch 45][Train on 403 [MSE: 0.0005  PSNR: 32.7904]][Val on 50 [MSE: 0.0005  PSNR: 32.8097]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 46][Train on 403 [MSE: 0.0005  PSNR: 32.7016]][Val on 50 [MSE: 0.0005  PSNR: 32.8516]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 47][Train on 403 [MSE: 0.0006  PSNR: 32.5761]][Val on 50 [MSE: 0.0005  PSNR: 32.8810]][Time: 0 m 55 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 48][Train on 403 [MSE: 0.0006  PSNR: 32.4567]][Val on 50 [MSE: 0.0005  PSNR: 32.8714]][Time: 0 m 56 s]\n",
            "[Epoch 49][Train on 403 [MSE: 0.0006  PSNR: 32.5436]][Val on 50 [MSE: 0.0005  PSNR: 32.8454]][Time: 0 m 55 s]\n",
            "[Epoch 50][Train on 403 [MSE: 0.0005  PSNR: 32.7433]][Val on 50 [MSE: 0.0005  PSNR: 32.8584]][Time: 0 m 55 s]\n",
            "[Epoch 51][Train on 403 [MSE: 0.0005  PSNR: 32.8215]][Val on 50 [MSE: 0.0005  PSNR: 32.8598]][Time: 0 m 55 s]\n",
            "[Epoch 52][Train on 403 [MSE: 0.0005  PSNR: 32.8493]][Val on 50 [MSE: 0.0005  PSNR: 32.8600]][Time: 0 m 55 s]\n",
            "[Epoch 53][Train on 403 [MSE: 0.0005  PSNR: 32.8664]][Val on 50 [MSE: 0.0005  PSNR: 32.8600]][Time: 0 m 55 s]\n",
            "[Epoch 54][Train on 403 [MSE: 0.0005  PSNR: 32.8796]][Val on 50 [MSE: 0.0005  PSNR: 32.8593]][Time: 0 m 55 s]\n",
            "[Epoch 55][Train on 403 [MSE: 0.0005  PSNR: 32.8909]][Val on 50 [MSE: 0.0005  PSNR: 32.8592]][Time: 0 m 55 s]\n",
            "[Epoch 56][Train on 403 [MSE: 0.0005  PSNR: 32.9010]][Val on 50 [MSE: 0.0005  PSNR: 32.8588]][Time: 0 m 55 s]\n",
            "[Epoch 57][Train on 403 [MSE: 0.0005  PSNR: 32.9099]][Val on 50 [MSE: 0.0005  PSNR: 32.8597]][Time: 0 m 55 s]\n",
            "[Epoch 58][Train on 403 [MSE: 0.0005  PSNR: 32.9179]][Val on 50 [MSE: 0.0005  PSNR: 32.8590]][Time: 0 m 55 s]\n",
            "[Epoch 59][Train on 403 [MSE: 0.0005  PSNR: 32.9253]][Val on 50 [MSE: 0.0005  PSNR: 32.8607]][Time: 0 m 55 s]\n",
            "------Best Combination saved [Epoch: 60 - Learning Rate: 0.0001]-------\n",
            "Best MSE: 0.000515104285441339\n",
            "Best PSNR: 32.881046295166016\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for numEpoch in epochList:\n",
        "    for lr in learningRateList:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        bestMse = 9000000000000000000.0             # Miglior MSE della singola combinazione\n",
        "        bestPsnr = -900000000000000000.0            # Miglior PSNR della singola combinazione\n",
        "\n",
        "        bestMSES, bestPSNRS, MSETrainList, MSEValList, PSNRTrainList, PSNRValList = training (trainDataload, trainDataloadNoise, valDataload, valDataloadNoise, numEpoch, model, criterion, optimizer, bestMse, bestPsnr, weightPath)\n",
        "\n",
        "        # Aggiorno i valori di miglior MSE\n",
        "        if bestMSES < bestMSEComb:\n",
        "            bestMSEComb = bestMSES\n",
        "            bestPSNRComb = bestPSNRS\n",
        "            # Caricamento dei pesi\n",
        "            torch.save(model.cpu().state_dict(), weightPathComb)\n",
        "            print(f\"------Best Combination saved [Epoch: {numEpoch} - Learning Rate: {lr}]-------\")\n",
        "            model.cuda()\n",
        "\n",
        "print(f\"Best MSE: {bestMSEComb}\")\n",
        "print(f\"Best PSNR: {bestPSNRComb}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc8e01c",
      "metadata": {
        "id": "3dc8e01c",
        "outputId": "2f946f8f-6a6a-47d0-853b-4650670a4c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test] [MSE: 0.0005  PSNR: 33.0072] [Time: 0 m 3 s]\n"
          ]
        }
      ],
      "source": [
        "# Percorsi output\n",
        "outputInPath = \"outputs/Denoiser/testSet/\"\n",
        "outputTruthPath = \"outputs/Denoiser/groundTruth/\"\n",
        "outputOutPath = \"outputs/Denoiser/results/\"\n",
        "os.makedirs(outputInPath, exist_ok=True)\n",
        "os.makedirs(outputTruthPath, exist_ok=True)\n",
        "os.makedirs(outputOutPath, exist_ok=True)\n",
        "\n",
        "# Testing\n",
        "outputsTest = testing(testDataload, testDataloadNoise, model, criterion, weightPathComb)\n",
        "\n",
        "# Iterazione sia su outputsTest che su testDataloadRic\n",
        "index = 1\n",
        "testIter = iter(testDataloadNoise)\n",
        "truthIter = iter(testDataload)\n",
        "\n",
        "# Salvataggio locale delle immagini \n",
        "for batchOut in outputsTest:\n",
        "    batchIn = next(testIter)                # Ottenimento del batch originale (e label se presente)\n",
        "    batchTruth = next(truthIter)\n",
        "\n",
        "    for j in range(batchOut.size(0)):\n",
        "        # --- Output ---\n",
        "        imgOut = batchOut[j].detach().cpu().clamp(0, 1)\n",
        "        imgOut = imgOut.permute(1, 2, 0).numpy()\n",
        "        pathOut = os.path.join(outputOutPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathOut, imgOut)\n",
        "        # --- Input ---\n",
        "        imgIn = batchIn[j].detach().cpu().clamp(0, 1)\n",
        "        imgIn = imgIn.permute(1, 2, 0).numpy()\n",
        "        pathIn = os.path.join(outputInPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathIn, imgIn)\n",
        "        # --- Ground Truth ---\n",
        "        imgTruth = batchTruth[j].detach().cpu().clamp(0, 1)\n",
        "        imgTruth = imgTruth.permute(1, 2, 0).numpy()\n",
        "        pathTruth = os.path.join(outputTruthPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathTruth, imgTruth)\n",
        "        index += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
