{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a48HzTgzH5df",
      "metadata": {
        "id": "a48HzTgzH5df"
      },
      "source": [
        "## 1. Download dei dati ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9f56cb",
      "metadata": {
        "id": "be9f56cb"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "!wget https://www.zemris.fer.hr/projects/LicensePlates/english/baza_slika.zip\n",
        "# Unzip file zip\n",
        "!unzip -o -j baza_slika.zip \"*.jpg\" -d dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f687007c",
      "metadata": {
        "id": "f687007c"
      },
      "source": [
        "## 2. Preparazione dei dati ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ce22ff",
      "metadata": {
        "id": "68ce22ff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from skimage.transform import rescale\n",
        "from skimage.util import view_as_windows\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "87d7819b",
      "metadata": {
        "id": "87d7819b"
      },
      "outputs": [],
      "source": [
        "# Percorso alla cartella che contiene le immagini\n",
        "datasetPath = \"dataset\"\n",
        "\n",
        "# Lista per salvare le immagini caricate\n",
        "imgList = []\n",
        "\n",
        "# Scorrimento di tutti i file nella cartella\n",
        "i = 0\n",
        "for fileName in os.listdir(datasetPath):\n",
        "    if fileName.lower().endswith(\".jpg\"):\n",
        "        filePath = os.path.join(datasetPath, fileName)\n",
        "        img = np.array(Image.open(filePath)).astype(np.float32) / 255.0\n",
        "        img = rescale(img, (1/1.66, 1/1.66, 1)) # Passaggio da 640x480 a 386x289\n",
        "        imgList.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a34481a",
      "metadata": {
        "id": "6a34481a"
      },
      "outputs": [],
      "source": [
        "# Padding automatico\n",
        "def pad_image_to_fit(img, windowShape, step):\n",
        "    h, w, _ = img.shape\n",
        "    wh, ww, _ = windowShape\n",
        "    pad_h = (np.ceil((h - wh) / step) * step + wh) - h\n",
        "    pad_w = (np.ceil((w - ww) / step) * step + ww) - w\n",
        "    pad_h = int(pad_h)\n",
        "    pad_w = int(pad_w)\n",
        "    return np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect'), pad_h, pad_w\n",
        "\n",
        "# Ridimensionamento dei blocchi\n",
        "def resize_blocks(blocks, scaleY, scaleX):\n",
        "    blocksRes = []\n",
        "    for i in range(blocks.shape[0]):\n",
        "        row = []\n",
        "        for j in range(blocks.shape[1]):\n",
        "            blockLow = rescale(blocks[i][j], (scaleY, scaleX), channel_axis=2)\n",
        "            blockUp = rescale(blockLow, (1/scaleY, 1/scaleX), order=1, channel_axis=2)\n",
        "            row.append(blockUp)\n",
        "        blocksRes.append(row)\n",
        "    return np.array(blocksRes)\n",
        "\n",
        "# Ricostruzione dell'immagine dai blocchi\n",
        "def reconstruct_img(blocks, stepY, stepX):\n",
        "    nRows, nCols, h, w, c = blocks.shape\n",
        "    H = (nRows - 1) * stepY + h\n",
        "    W = (nCols - 1) * stepX + w\n",
        "    canvas = np.zeros((H, W, c), dtype=np.float64)\n",
        "    weight = np.zeros((H, W, c), dtype=np.float64)\n",
        "    for i in range(nRows):\n",
        "        for j in range(nCols):\n",
        "            top = i * stepY\n",
        "            left = j * stepX\n",
        "            canvas[top:top+h, left:left+w, :] += blocks[i, j]\n",
        "            weight[top:top+h, left:left+w, :] += 1\n",
        "    return (canvas / np.maximum(weight, 1)).astype(np.float64)\n",
        "\n",
        "# Funzione principale\n",
        "def downscale_data(img, windowShape, scale, step):\n",
        "    img_padded, pad_h, pad_w = pad_image_to_fit(img, windowShape, step)\n",
        "    blocks = view_as_windows(img_padded, windowShape, step).squeeze()\n",
        "    blocksLow = resize_blocks(blocks, scale, scale)\n",
        "    imgLow = reconstruct_img(blocksLow, step, step)\n",
        "    # Rimozione del padding\n",
        "    return imgLow[:img.shape[0], :img.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd875f2",
      "metadata": {
        "id": "0bd875f2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "# Modifica del dataset\n",
        "class ImgListDataset(Dataset):\n",
        "    def __init__(self, imgList):\n",
        "        self.imgList = imgList\n",
        "        self.target_size = (289, 386)           # Altezza e larghezza desiderata\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),            # Conversione a immagine\n",
        "            transforms.Resize(self.target_size),\n",
        "            transforms.ToTensor()               # Conversione a tensore\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgList)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgList[idx]\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22cf6d4e",
      "metadata": {
        "id": "22cf6d4e"
      },
      "outputs": [],
      "source": [
        "# Divisione dell'intero dataset in training set, validation set e test set (80%, 10% e 10%)\n",
        "trainSet, valSet, testSet = random_split(imgList, [0.8, 0.1, 0.1])\n",
        "\n",
        "windowShape = (96,96,3)\n",
        "scale = 0.5\n",
        "step = 24\n",
        "\n",
        "# Creazione dei dataset di immagini ricostruite (downscale-upscale)\n",
        "trainSetRic = []\n",
        "valSetRic = []\n",
        "testSetRic = []\n",
        "\n",
        "for el in trainSet:\n",
        "    imgLow = downscale_data(el, windowShape, scale, step)\n",
        "    trainSetRic.append(imgLow)\n",
        "\n",
        "for el in valSet:\n",
        "    imgLow = downscale_data(el, windowShape, scale, step)\n",
        "    valSetRic.append(imgLow)\n",
        "\n",
        "for el in testSet:\n",
        "    imgLow = downscale_data(el, windowShape, scale, step)\n",
        "    testSetRic.append(imgLow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af2e0e1",
      "metadata": {
        "id": "2af2e0e1",
        "outputId": "2980e7fd-3485-4ce0-8b9f-13fe4b5d246c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Effettuata suddivisione:\n",
            "- Training-set: 403 campioni.\n",
            "- Validation-set: 50 campioni.\n",
            "- Test-set: 50 campioni.\n",
            "- Training-set Ric: 403 campioni.\n",
            "- Validation-set Ric: 50 campioni.\n",
            "- Test-set Ric: 50 campioni.\n"
          ]
        }
      ],
      "source": [
        "# Definizione variabili\n",
        "batchSize = 6\n",
        "numWorkers = 4\n",
        "\n",
        "# Modifica del dataset per le immagini originali\n",
        "trainSetDataset = ImgListDataset(trainSet)\n",
        "valSetDataset = ImgListDataset(valSet)\n",
        "testSetDataset = ImgListDataset(testSet)\n",
        "\n",
        "# Dataloader per le immagini originali\n",
        "trainDataload = DataLoader(trainSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "valDataload = DataLoader(valSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "testDataload = DataLoader(testSetDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "\n",
        "# Modifica del dataset per le immagini ricostruite (downscale-upscale)\n",
        "trainSetRicDataset = ImgListDataset(trainSetRic)\n",
        "valSetRicDataset = ImgListDataset(valSetRic)\n",
        "testSetRicDataset = ImgListDataset(testSetRic)\n",
        "\n",
        "# Dataloader per le immagini ricostruite (downscale-upscale)\n",
        "trainDataloadRic = DataLoader(trainSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "valDataloadRic = DataLoader(valSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "testDataloadRic = DataLoader(testSetRicDataset, batch_size=batchSize, num_workers=numWorkers)\n",
        "\n",
        "print(\"Effettuata suddivisione:\")\n",
        "print(f\"- Training-set: {len(trainSet)} campioni.\")\n",
        "print(f\"- Validation-set: {len(valSet)} campioni.\")\n",
        "print(f\"- Test-set: {len(testSet)} campioni.\")\n",
        "print(f\"- Training-set Ric: {len(trainSetRic)} campioni.\")\n",
        "print(f\"- Validation-set Ric: {len(valSetRic)} campioni.\")\n",
        "print(f\"- Test-set Ric: {len(testSetRic)} campioni.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b895ccf1",
      "metadata": {
        "id": "b895ccf1"
      },
      "source": [
        "## 3. Architettura ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440f2cea",
      "metadata": {
        "id": "440f2cea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=64, kernel_size=3, padding=1):\n",
        "        super(DnCNN, self).__init__()\n",
        "        # in_channel = 3 poichè 3 canali\n",
        "        # out_channel = 64 come scritto nella traccia (num feat)\n",
        "        # kernel_size = 3 come scritto nella traccia (dim spaziale 3x3)\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # Iter 1: Convolution + ReLU\n",
        "        layers.append(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        # Iters 2-16: Convolution + BatchNorm + ReLU\n",
        "        for i in range(15):\n",
        "            layers.append(nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))                    # Corrisponde al numero di canali di output del livello precedente\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        # Iters 17: Convolution\n",
        "        layers.append(nn.Conv2d(in_channels=out_channels, out_channels=in_channels, kernel_size=kernel_size, padding=padding))\n",
        "\n",
        "        # *layers corrisponde a layers[0],layers[1],..., quindi già spalmati come singoli elementi\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        self.apply(self.kernel_initializer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "    # Equivalente a kernel_inizializer=\"Orthogonal\" in pytorch\n",
        "    def kernel_initializer(self, module):\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            nn.init.orthogonal_(module.weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76be591b",
      "metadata": {
        "id": "76be591b"
      },
      "source": [
        "## 4. Addestramento ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d154678e",
      "metadata": {
        "id": "d154678e"
      },
      "outputs": [],
      "source": [
        "# Importiamo le librerie necessarie\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c4f5aa",
      "metadata": {
        "id": "52c4f5aa",
        "outputId": "c71eaa96-2f86-43aa-917a-fa1a8e56e753"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Abilitazione il dispositivo GPU per il training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770ddf07",
      "metadata": {
        "id": "770ddf07"
      },
      "outputs": [],
      "source": [
        "# Legenda dataloader:\n",
        "#   - dlTrain = immagini originali training\n",
        "#   - dlTrainRic = immagini ricostruite (downscalate-upscalate) training\n",
        "#   - dlVal = immagini originali validation\n",
        "#   - dlValRic = immagini ricostruite (downscalate-upscalate) validation\n",
        "def training (dlTrain, dlTrainRic, dlVal, dlValRic, numEpoch, model, criterion, optimizer, bestMse, bestPsnr, outputPath):\n",
        "\n",
        "    # Liste dei risultati definite per la visualizzazione\n",
        "    MSETrainList = []\n",
        "    MSEValList = []\n",
        "    PSNRTrainList = []\n",
        "    PSNRValList = []\n",
        "\n",
        "    # Iterazione per ogni epoch\n",
        "    for epoch in range(numEpoch):\n",
        "\n",
        "        model.cuda()\n",
        "        # Conteggio del tempo per misurare la durata di un'epoca\n",
        "        since = time.time()\n",
        "\n",
        "        # Inizializzazione delle variabili\n",
        "        modelMseTrain = 0.0\n",
        "        totalSize = 0\n",
        "\n",
        "        # Modello impostato in traning mode\n",
        "        model.train()\n",
        "\n",
        "        # Iterazione per ogni batch\n",
        "        # Devo iterare su i 2 dataloader contemporaneamente, per fare ciò utilizzo zip\n",
        "        for (inputsTrain, inputsRic) in zip(dlTrain, dlTrainRic):\n",
        "\n",
        "            # Converto gli input in tensori float e li carico nella GPU\n",
        "            inputsTrain = inputsTrain.type(torch.FloatTensor).cuda()\n",
        "            inputsRic = inputsRic.type(torch.FloatTensor).cuda()\n",
        "\n",
        "            # Reset dei gradienti, altrimenti i vecchi gradienti sono sommati ai nuovi, piuttosto\n",
        "            # che essere sovrascritti\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Calcolo dettagli e ricostruzione immagine\n",
        "            yTrain = model(inputsRic)\n",
        "            y = yTrain + inputsRic\n",
        "\n",
        "            # Calcolo della MSE\n",
        "            loss = criterion(y, inputsTrain)\n",
        "            # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "            # media per il numero di elementi per ottenere la somma totale della loss\n",
        "            modelMseTrain += loss.item() * inputsTrain.size(0)\n",
        "            totalSize += inputsTrain.size(0)\n",
        "\n",
        "            # Calcolando il gradiente del tensore attuale\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()        # Aggiornamento dei parametri\n",
        "            optimizer.zero_grad()   # Azzeramento dei gradienti per il prossimo ciclo di accumulo\n",
        "            \n",
        "\n",
        "        # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "        modelMseEpochTrain = modelMseTrain/totalSize\n",
        "        modelPsnrEpochTrain = 10 * torch.log10(torch.tensor(1/modelMseEpochTrain))\n",
        "\n",
        "        # Salvataggio dei pesi per ogni iterazione (disabilitato)\n",
        "        # torch.save(model.state_dict(), outputPath + \"train_weights.pth\")\n",
        "\n",
        "        # Modello impostato in validation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Inizializzazione delle variabili\n",
        "        modelMseVal = 0.0\n",
        "        totalSizeVal = 0\n",
        "\n",
        "        with torch.no_grad():               # Disattiva il calcolo dei gradienti\n",
        "        # Iterazione per ogni bach\n",
        "        # Devo iterare su i 2 dataloader contemporaneamente, per fare ciò utilizzo zip\n",
        "            for (inputsVal, inputsValRic) in zip(dlVal, dlValRic):\n",
        "\n",
        "                # Converto gli input in tensori float e li carico nella GPU\n",
        "                inputsVal = inputsVal.type(torch.FloatTensor).cuda()\n",
        "                inputsValRic = inputsValRic.type(torch.FloatTensor).cuda()\n",
        "\n",
        "                # Calcolo dettagli\n",
        "                yVal = model(inputsValRic)\n",
        "                y = yVal + inputsValRic\n",
        "\n",
        "                # Calcolo della MSE\n",
        "                loss = criterion(y, inputsVal)\n",
        "                # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "                # media per il numero di elementi per ottenere la somma totale della loss\n",
        "                modelMseVal += loss.item() * inputsVal.size(0)\n",
        "                totalSizeVal += inputsVal.size(0)\n",
        "\n",
        "            # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "            modelMseEpochVal = modelMseVal/totalSizeVal\n",
        "            modelPsnrEpochVal = 10 * torch.log10(torch.tensor(1/modelMseEpochVal))\n",
        "            timeElapsed = time.time()-since\n",
        "\n",
        "        print('[Epoch %d][Train on %d [MSE: %.4f  PSNR: %.4f]][Val on %d [MSE: %.4f  PSNR: %.4f]][Time: %.0f m %.0f s]'\n",
        "                %(epoch, totalSize, modelMseEpochTrain, modelPsnrEpochTrain, totalSizeVal, modelMseEpochVal,\n",
        "                modelPsnrEpochVal, timeElapsed // 60, timeElapsed % 60))\n",
        "\n",
        "        # Salvaggio dei risultati migliori\n",
        "        if (modelMseEpochVal < bestMse):\n",
        "            print(\"-------Saving best weights-------\")\n",
        "            bestMse = modelMseEpochVal\n",
        "            bestPsnr = modelPsnrEpochVal\n",
        "            # Salvataggio dei migliori risultati\n",
        "            try:\n",
        "                torch.save(model.cpu().state_dict(), outputPath)\n",
        "                print(\"-------Best weights saved-------\")\n",
        "            except Exception as e:\n",
        "                print(\"Error:\", e)\n",
        "\n",
        "        # Salvataggio dei risultati per la visualizzazione\n",
        "        MSETrainList.append(modelMseEpochTrain)\n",
        "        MSEValList.append(modelMseEpochVal)\n",
        "        PSNRTrainList.append(modelPsnrEpochTrain)\n",
        "        PSNRValList.append(modelPsnrEpochVal)\n",
        "\n",
        "    return bestMse, bestPsnr, MSETrainList, MSEValList, PSNRTrainList, PSNRValList\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13e3c40",
      "metadata": {
        "id": "c13e3c40"
      },
      "outputs": [],
      "source": [
        "# Funzione di testing\n",
        "\n",
        "def testing (dlTest, dlTestRic, model, criterion, weightPath):\n",
        "\n",
        "    # Caricamento dei pesi\n",
        "    model.load_state_dict(torch.load(weightPath, map_location=torch.device(\"cpu\")))\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "    # Conteggio del tempo per misurare la durata di un'epoca\n",
        "    since = time.time()\n",
        "\n",
        "    # Inizializzazione delle variabili\n",
        "    modelMseTest = 0.0\n",
        "    totalSize = 0\n",
        "    outputsTest = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Iterazione su batch\n",
        "    with torch.no_grad():               # Disattiva il calcolo dei gradienti\n",
        "        for (inputsTest, inputsTestRic) in zip(dlTest, dlTestRic):\n",
        "\n",
        "\n",
        "            # Converto gli input in tensori float e li carico nella GPU\n",
        "            inputsTest = inputsTest.type(torch.FloatTensor).cuda()\n",
        "            inputsTestRic = inputsTestRic.type(torch.FloatTensor).cuda()\n",
        "\n",
        "            # Calcolo dettagli e ricostruzione immagine\n",
        "            yTest = model(inputsTestRic)\n",
        "            y = yTest + inputsTestRic\n",
        "            outputsTest.append(y)\n",
        "\n",
        "            # Calcolo della MSE\n",
        "            loss = criterion(y, inputsTest)\n",
        "            # size(0) restituisce il numero di campioni nel batch, quindi si sta moltiplicando la loss\n",
        "            # media per il numero di elementi per ottenere la somma totale della loss\n",
        "            modelMseTest += loss.item() * inputsTest.size(0)\n",
        "            totalSize += inputsTest.size(0)\n",
        "\n",
        "\n",
        "        # Calcolo della MSE medio e del PSNR medio  dell'epoch\n",
        "        modelMseEpochTest = modelMseTest/totalSize\n",
        "        modelPsnrEpochTest = 10 * torch.log10(torch.tensor(1/modelMseEpochTest))\n",
        "        timeElapsed = time.time()-since\n",
        "\n",
        "        print(\"[Test] [MSE: %.4f  PSNR: %.4f] [Time: %.0f m %.0f s]\"\n",
        "          %(modelMseEpochTest, modelPsnrEpochTest, timeElapsed // 60, timeElapsed % 60))\n",
        "\n",
        "        return outputsTest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6fc029",
      "metadata": {
        "id": "ca6fc029"
      },
      "source": [
        "## 5. Valutazione delle prestazioni ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "627e8766",
      "metadata": {
        "id": "627e8766"
      },
      "outputs": [],
      "source": [
        "def graphVisualization(MseModelTrain, MseModelVal, PSNRModelTrain, PSNRModelVal):\n",
        "\n",
        "    # Visualizzazione delle liste come subplot\n",
        "    fig, ax = plt.subplots(2, 1, figsize=(4, 5), constrained_layout=True)\n",
        "\n",
        "    # Visualizzazione di MSE Training vs Validation\n",
        "    ax[0].set_xlabel(\"Epoch\", fontsize=10)\n",
        "    ax[0].set_ylabel(\"MSE\", fontsize=10)\n",
        "    ax[0].set_title(\"MSE Training vs Validation\", fontsize=10)\n",
        "    ax[0].plot(range(len(MseModelTrain)), MseModelTrain, color=\"r\", marker=\"o\", label=\"Training MSE\")\n",
        "    ax[0].plot(range(len(MseModelVal)), MseModelVal, color=\"b\", marker=\"o\", label=\"Validation MSE\")\n",
        "    ax[0].set_xlim([0, max(len(MseModelTrain), len(MseModelVal))-0.5])\n",
        "    ax[0].set_ylim([0.02, 0.2])\n",
        "    ax[0].legend()\n",
        "    ax[0].grid(True)\n",
        "\n",
        "    # Visualizzazione di PSNR Training vs Validation\n",
        "    ax[1].set_xlabel(\"Epoch\", fontsize=10)\n",
        "    ax[1].set_ylabel(\"PSNR\", fontsize=10)\n",
        "    ax[1].set_title(\"PSNR Training vs Validation\", fontsize=10)\n",
        "    ax[1].plot(range(len(PSNRModelTrain)), PSNRModelTrain, color=\"r\", marker=\"o\", label=\"Training PSNR\")\n",
        "    ax[1].plot(range(len(PSNRModelVal)), PSNRModelVal, color=\"b\", marker=\"o\", label=\"Validation PSNR\")\n",
        "    ax[1].set_xlim([0, max(len(PSNRModelTrain), len(PSNRModelVal))-0.5])\n",
        "    ax[1].set_ylim([50, 100])\n",
        "    ax[1].legend()\n",
        "    ax[1].grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5cd243",
      "metadata": {
        "id": "6b5cd243"
      },
      "outputs": [],
      "source": [
        "# Iper-parametri\n",
        "epochList = [20, 60]\n",
        "learningRateList = [0.01, 0.001, 0.0001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25666195",
      "metadata": {
        "id": "25666195"
      },
      "outputs": [],
      "source": [
        "# Main\n",
        "import torch.optim as optim\n",
        "\n",
        "model = DnCNN().cuda()\n",
        "criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "bestMSEComb = 9000000000000000000.0              # Miglior MSE tra tutte le combinazioni\n",
        "bestPSNRComb = -900000000000000000.0             # Miglior PSNR tra tutte le combinazioni\n",
        "\n",
        "# Definizione dei percorsi per il salvataggio dei pesi\n",
        "weightPath = \"best_weights.pth\"\n",
        "weightPathComb = \"best_weights_lr.pth\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfc263c",
      "metadata": {
        "id": "8dfc263c",
        "outputId": "3e36426b-4069-4919-d0a2-e62a2930b6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0][Train on 403 [MSE: 0.1794  PSNR: 7.4619]][Val on 50 [MSE: 0.0083  PSNR: 20.8019]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0021  PSNR: 26.7456]][Val on 50 [MSE: 0.0018  PSNR: 27.3765]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0019  PSNR: 27.2462]][Val on 50 [MSE: 0.0017  PSNR: 27.6018]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0019  PSNR: 27.2784]][Val on 50 [MSE: 0.0016  PSNR: 27.8410]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0019  PSNR: 27.3145]][Val on 50 [MSE: 0.0016  PSNR: 27.9267]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0019  PSNR: 27.2631]][Val on 50 [MSE: 0.0021  PSNR: 26.8542]][Time: 0 m 52 s]\n",
            "[Epoch 6][Train on 403 [MSE: 0.0021  PSNR: 26.7370]][Val on 50 [MSE: 0.0016  PSNR: 27.8736]][Time: 0 m 52 s]\n",
            "[Epoch 7][Train on 403 [MSE: 0.0021  PSNR: 26.7881]][Val on 50 [MSE: 0.0032  PSNR: 24.9156]][Time: 0 m 51 s]\n",
            "[Epoch 8][Train on 403 [MSE: 0.0020  PSNR: 27.0784]][Val on 50 [MSE: 0.0020  PSNR: 26.9505]][Time: 0 m 50 s]\n",
            "[Epoch 9][Train on 403 [MSE: 0.0019  PSNR: 27.2683]][Val on 50 [MSE: 0.0017  PSNR: 27.6101]][Time: 0 m 51 s]\n",
            "[Epoch 10][Train on 403 [MSE: 0.0018  PSNR: 27.3718]][Val on 50 [MSE: 0.0017  PSNR: 27.8026]][Time: 0 m 50 s]\n",
            "[Epoch 11][Train on 403 [MSE: 0.0018  PSNR: 27.4051]][Val on 50 [MSE: 0.0016  PSNR: 27.8562]][Time: 0 m 52 s]\n",
            "[Epoch 12][Train on 403 [MSE: 0.0018  PSNR: 27.4130]][Val on 50 [MSE: 0.0017  PSNR: 27.8201]][Time: 0 m 53 s]\n",
            "[Epoch 13][Train on 403 [MSE: 0.0018  PSNR: 27.4139]][Val on 50 [MSE: 0.0017  PSNR: 27.7963]][Time: 0 m 53 s]\n",
            "[Epoch 14][Train on 403 [MSE: 0.0018  PSNR: 27.4194]][Val on 50 [MSE: 0.0016  PSNR: 27.9210]][Time: 0 m 53 s]\n",
            "[Epoch 15][Train on 403 [MSE: 0.0018  PSNR: 27.4279]][Val on 50 [MSE: 0.0016  PSNR: 27.9953]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0018  PSNR: 27.4299]][Val on 50 [MSE: 0.0016  PSNR: 28.0148]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0018  PSNR: 27.4296]][Val on 50 [MSE: 0.0016  PSNR: 28.0253]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0018  PSNR: 27.4414]][Val on 50 [MSE: 0.0016  PSNR: 28.0228]][Time: 0 m 50 s]\n",
            "[Epoch 19][Train on 403 [MSE: 0.0018  PSNR: 27.4500]][Val on 50 [MSE: 0.0016  PSNR: 28.0244]][Time: 0 m 50 s]\n",
            "------Best Combination saved [Epoch: 20 - Learning Rate: 0.01]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0021  PSNR: 26.7021]][Val on 50 [MSE: 0.0018  PSNR: 27.3921]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0018  PSNR: 27.4061]][Val on 50 [MSE: 0.0016  PSNR: 27.9782]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0018  PSNR: 27.4305]][Val on 50 [MSE: 0.0016  PSNR: 27.8749]][Time: 0 m 50 s]\n",
            "[Epoch 3][Train on 403 [MSE: 0.0018  PSNR: 27.4449]][Val on 50 [MSE: 0.0017  PSNR: 27.7921]][Time: 0 m 50 s]\n",
            "[Epoch 4][Train on 403 [MSE: 0.0021  PSNR: 26.7247]][Val on 50 [MSE: 0.0054  PSNR: 22.6897]][Time: 0 m 50 s]\n",
            "[Epoch 5][Train on 403 [MSE: 0.0022  PSNR: 26.5231]][Val on 50 [MSE: 0.0017  PSNR: 27.6442]][Time: 0 m 50 s]\n",
            "[Epoch 6][Train on 403 [MSE: 0.0018  PSNR: 27.3594]][Val on 50 [MSE: 0.0016  PSNR: 27.9511]][Time: 0 m 50 s]\n",
            "[Epoch 7][Train on 403 [MSE: 0.0018  PSNR: 27.3990]][Val on 50 [MSE: 0.0016  PSNR: 27.9081]][Time: 0 m 50 s]\n",
            "[Epoch 8][Train on 403 [MSE: 0.0018  PSNR: 27.4144]][Val on 50 [MSE: 0.0016  PSNR: 27.9640]][Time: 0 m 50 s]\n",
            "[Epoch 9][Train on 403 [MSE: 0.0018  PSNR: 27.4306]][Val on 50 [MSE: 0.0016  PSNR: 27.9463]][Time: 0 m 50 s]\n",
            "[Epoch 10][Train on 403 [MSE: 0.0018  PSNR: 27.4329]][Val on 50 [MSE: 0.0016  PSNR: 27.9468]][Time: 0 m 50 s]\n",
            "[Epoch 11][Train on 403 [MSE: 0.0018  PSNR: 27.4372]][Val on 50 [MSE: 0.0016  PSNR: 27.9485]][Time: 0 m 50 s]\n",
            "[Epoch 12][Train on 403 [MSE: 0.0018  PSNR: 27.4417]][Val on 50 [MSE: 0.0016  PSNR: 27.9486]][Time: 0 m 50 s]\n",
            "[Epoch 13][Train on 403 [MSE: 0.0018  PSNR: 27.4463]][Val on 50 [MSE: 0.0016  PSNR: 27.9528]][Time: 0 m 50 s]\n",
            "[Epoch 14][Train on 403 [MSE: 0.0018  PSNR: 27.4529]][Val on 50 [MSE: 0.0016  PSNR: 27.9659]][Time: 0 m 50 s]\n",
            "[Epoch 15][Train on 403 [MSE: 0.0018  PSNR: 27.4634]][Val on 50 [MSE: 0.0016  PSNR: 27.9853]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0018  PSNR: 27.4800]][Val on 50 [MSE: 0.0016  PSNR: 28.0218]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0018  PSNR: 27.5047]][Val on 50 [MSE: 0.0016  PSNR: 28.0333]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0018  PSNR: 27.5357]][Val on 50 [MSE: 0.0016  PSNR: 28.0829]][Time: 0 m 50 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0017  PSNR: 27.5808]][Val on 50 [MSE: 0.0016  PSNR: 28.0959]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "------Best Combination saved [Epoch: 20 - Learning Rate: 0.001]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0017  PSNR: 27.6599]][Val on 50 [MSE: 0.0015  PSNR: 28.2610]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0017  PSNR: 27.7519]][Val on 50 [MSE: 0.0015  PSNR: 28.3471]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0016  PSNR: 27.8592]][Val on 50 [MSE: 0.0014  PSNR: 28.4323]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0016  PSNR: 27.9495]][Val on 50 [MSE: 0.0014  PSNR: 28.4970]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0016  PSNR: 28.0256]][Val on 50 [MSE: 0.0014  PSNR: 28.5776]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0015  PSNR: 28.0986]][Val on 50 [MSE: 0.0014  PSNR: 28.6511]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0015  PSNR: 28.1769]][Val on 50 [MSE: 0.0013  PSNR: 28.7212]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0015  PSNR: 28.2614]][Val on 50 [MSE: 0.0013  PSNR: 28.7965]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0015  PSNR: 28.3517]][Val on 50 [MSE: 0.0013  PSNR: 28.8643]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0014  PSNR: 28.4420]][Val on 50 [MSE: 0.0013  PSNR: 28.9260]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 10][Train on 403 [MSE: 0.0014  PSNR: 28.5267]][Val on 50 [MSE: 0.0013  PSNR: 28.9845]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0014  PSNR: 28.6050]][Val on 50 [MSE: 0.0012  PSNR: 29.0391]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0014  PSNR: 28.6761]][Val on 50 [MSE: 0.0012  PSNR: 29.0970]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0013  PSNR: 28.7411]][Val on 50 [MSE: 0.0012  PSNR: 29.1483]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 14][Train on 403 [MSE: 0.0013  PSNR: 28.8002]][Val on 50 [MSE: 0.0012  PSNR: 29.1974]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 15][Train on 403 [MSE: 0.0013  PSNR: 28.8536]][Val on 50 [MSE: 0.0012  PSNR: 29.2379]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0013  PSNR: 28.9012]][Val on 50 [MSE: 0.0012  PSNR: 29.2796]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0013  PSNR: 28.9461]][Val on 50 [MSE: 0.0012  PSNR: 29.3098]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0013  PSNR: 28.9881]][Val on 50 [MSE: 0.0012  PSNR: 29.3387]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0013  PSNR: 29.0277]][Val on 50 [MSE: 0.0012  PSNR: 29.3639]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "------Best Combination saved [Epoch: 20 - Learning Rate: 0.0001]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0291  PSNR: 15.3605]][Val on 50 [MSE: 0.0045  PSNR: 23.4485]][Time: 0 m 52 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0018  PSNR: 27.3472]][Val on 50 [MSE: 0.0017  PSNR: 27.8059]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0018  PSNR: 27.4107]][Val on 50 [MSE: 0.0016  PSNR: 27.8859]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0018  PSNR: 27.4192]][Val on 50 [MSE: 0.0016  PSNR: 27.9060]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0018  PSNR: 27.4249]][Val on 50 [MSE: 0.0017  PSNR: 27.7473]][Time: 0 m 51 s]\n",
            "[Epoch 5][Train on 403 [MSE: 0.0018  PSNR: 27.4244]][Val on 50 [MSE: 0.0017  PSNR: 27.6808]][Time: 0 m 51 s]\n",
            "[Epoch 6][Train on 403 [MSE: 0.0018  PSNR: 27.4231]][Val on 50 [MSE: 0.0017  PSNR: 27.6661]][Time: 0 m 51 s]\n",
            "[Epoch 7][Train on 403 [MSE: 0.0018  PSNR: 27.4249]][Val on 50 [MSE: 0.0017  PSNR: 27.7476]][Time: 0 m 51 s]\n",
            "[Epoch 8][Train on 403 [MSE: 0.0018  PSNR: 27.4267]][Val on 50 [MSE: 0.0016  PSNR: 27.8369]][Time: 0 m 51 s]\n",
            "[Epoch 9][Train on 403 [MSE: 0.0018  PSNR: 27.4292]][Val on 50 [MSE: 0.0016  PSNR: 27.9285]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 10][Train on 403 [MSE: 0.0018  PSNR: 27.4329]][Val on 50 [MSE: 0.0016  PSNR: 27.9658]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0018  PSNR: 27.4351]][Val on 50 [MSE: 0.0016  PSNR: 27.9745]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0018  PSNR: 27.4360]][Val on 50 [MSE: 0.0016  PSNR: 27.9693]][Time: 0 m 51 s]\n",
            "[Epoch 13][Train on 403 [MSE: 0.0018  PSNR: 27.4360]][Val on 50 [MSE: 0.0016  PSNR: 27.9545]][Time: 0 m 51 s]\n",
            "[Epoch 14][Train on 403 [MSE: 0.0018  PSNR: 27.4361]][Val on 50 [MSE: 0.0016  PSNR: 27.9425]][Time: 0 m 51 s]\n",
            "[Epoch 15][Train on 403 [MSE: 0.0018  PSNR: 27.4361]][Val on 50 [MSE: 0.0016  PSNR: 27.9601]][Time: 0 m 51 s]\n",
            "[Epoch 16][Train on 403 [MSE: 0.0018  PSNR: 27.4375]][Val on 50 [MSE: 0.0016  PSNR: 27.9897]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0018  PSNR: 27.4383]][Val on 50 [MSE: 0.0016  PSNR: 27.9994]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0018  PSNR: 27.4387]][Val on 50 [MSE: 0.0016  PSNR: 27.9687]][Time: 0 m 51 s]\n",
            "[Epoch 19][Train on 403 [MSE: 0.0018  PSNR: 27.4383]][Val on 50 [MSE: 0.0016  PSNR: 28.0079]][Time: 0 m 54 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 20][Train on 403 [MSE: 0.0018  PSNR: 27.4388]][Val on 50 [MSE: 0.0016  PSNR: 28.0088]][Time: 0 m 53 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 21][Train on 403 [MSE: 0.0018  PSNR: 27.4382]][Val on 50 [MSE: 0.0016  PSNR: 28.0138]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 22][Train on 403 [MSE: 0.0018  PSNR: 27.4370]][Val on 50 [MSE: 0.0016  PSNR: 28.0153]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 23][Train on 403 [MSE: 0.0018  PSNR: 27.4365]][Val on 50 [MSE: 0.0016  PSNR: 27.9946]][Time: 0 m 51 s]\n",
            "[Epoch 24][Train on 403 [MSE: 0.0018  PSNR: 27.4367]][Val on 50 [MSE: 0.0016  PSNR: 27.9836]][Time: 0 m 51 s]\n",
            "[Epoch 25][Train on 403 [MSE: 0.0018  PSNR: 27.4373]][Val on 50 [MSE: 0.0016  PSNR: 27.9367]][Time: 0 m 51 s]\n",
            "[Epoch 26][Train on 403 [MSE: 0.0018  PSNR: 27.4325]][Val on 50 [MSE: 0.0016  PSNR: 27.9223]][Time: 0 m 51 s]\n",
            "[Epoch 27][Train on 403 [MSE: 0.0018  PSNR: 27.4299]][Val on 50 [MSE: 0.0016  PSNR: 27.9645]][Time: 0 m 51 s]\n",
            "[Epoch 28][Train on 403 [MSE: 0.0018  PSNR: 27.4303]][Val on 50 [MSE: 0.0016  PSNR: 27.9634]][Time: 0 m 51 s]\n",
            "[Epoch 29][Train on 403 [MSE: 0.0018  PSNR: 27.4304]][Val on 50 [MSE: 0.0016  PSNR: 27.8786]][Time: 0 m 51 s]\n",
            "[Epoch 30][Train on 403 [MSE: 0.0018  PSNR: 27.4223]][Val on 50 [MSE: 0.0016  PSNR: 27.8398]][Time: 0 m 51 s]\n",
            "[Epoch 31][Train on 403 [MSE: 0.0018  PSNR: 27.3923]][Val on 50 [MSE: 0.0017  PSNR: 27.7736]][Time: 0 m 51 s]\n",
            "[Epoch 32][Train on 403 [MSE: 0.0020  PSNR: 27.0485]][Val on 50 [MSE: 0.0019  PSNR: 27.2014]][Time: 0 m 51 s]\n",
            "[Epoch 33][Train on 403 [MSE: 0.0019  PSNR: 27.2824]][Val on 50 [MSE: 0.0017  PSNR: 27.7064]][Time: 0 m 51 s]\n",
            "[Epoch 34][Train on 403 [MSE: 0.0019  PSNR: 27.3095]][Val on 50 [MSE: 0.0016  PSNR: 27.8731]][Time: 0 m 51 s]\n",
            "[Epoch 35][Train on 403 [MSE: 0.0019  PSNR: 27.2142]][Val on 50 [MSE: 0.0017  PSNR: 27.7883]][Time: 0 m 51 s]\n",
            "[Epoch 36][Train on 403 [MSE: 0.0019  PSNR: 27.2385]][Val on 50 [MSE: 0.0017  PSNR: 27.6171]][Time: 0 m 51 s]\n",
            "[Epoch 37][Train on 403 [MSE: 0.0022  PSNR: 26.5926]][Val on 50 [MSE: 0.0032  PSNR: 24.9359]][Time: 0 m 51 s]\n",
            "[Epoch 38][Train on 403 [MSE: 0.0021  PSNR: 26.7674]][Val on 50 [MSE: 0.0017  PSNR: 27.6947]][Time: 0 m 51 s]\n",
            "[Epoch 39][Train on 403 [MSE: 0.0018  PSNR: 27.4076]][Val on 50 [MSE: 0.0016  PSNR: 27.9367]][Time: 0 m 51 s]\n",
            "[Epoch 40][Train on 403 [MSE: 0.0018  PSNR: 27.4210]][Val on 50 [MSE: 0.0016  PSNR: 27.9333]][Time: 0 m 51 s]\n",
            "[Epoch 41][Train on 403 [MSE: 0.0018  PSNR: 27.4156]][Val on 50 [MSE: 0.0016  PSNR: 27.9007]][Time: 0 m 51 s]\n",
            "[Epoch 42][Train on 403 [MSE: 0.0018  PSNR: 27.4070]][Val on 50 [MSE: 0.0016  PSNR: 27.9659]][Time: 0 m 51 s]\n",
            "[Epoch 43][Train on 403 [MSE: 0.0018  PSNR: 27.3667]][Val on 50 [MSE: 0.0016  PSNR: 27.9367]][Time: 0 m 51 s]\n",
            "[Epoch 44][Train on 403 [MSE: 0.0018  PSNR: 27.3285]][Val on 50 [MSE: 0.0016  PSNR: 27.9144]][Time: 0 m 51 s]\n",
            "[Epoch 45][Train on 403 [MSE: 0.0019  PSNR: 27.1124]][Val on 50 [MSE: 0.0016  PSNR: 27.9809]][Time: 0 m 51 s]\n",
            "[Epoch 46][Train on 403 [MSE: 0.0019  PSNR: 27.3209]][Val on 50 [MSE: 0.0016  PSNR: 28.0031]][Time: 0 m 51 s]\n",
            "[Epoch 47][Train on 403 [MSE: 0.0019  PSNR: 27.1839]][Val on 50 [MSE: 0.0016  PSNR: 27.9812]][Time: 0 m 51 s]\n",
            "[Epoch 48][Train on 403 [MSE: 0.0019  PSNR: 27.2610]][Val on 50 [MSE: 0.0016  PSNR: 27.9429]][Time: 0 m 51 s]\n",
            "[Epoch 49][Train on 403 [MSE: 0.0019  PSNR: 27.2399]][Val on 50 [MSE: 0.0016  PSNR: 27.9347]][Time: 0 m 51 s]\n",
            "[Epoch 50][Train on 403 [MSE: 0.0019  PSNR: 27.2282]][Val on 50 [MSE: 0.0016  PSNR: 27.9802]][Time: 0 m 51 s]\n",
            "[Epoch 51][Train on 403 [MSE: 0.0019  PSNR: 27.1876]][Val on 50 [MSE: 0.0017  PSNR: 27.6889]][Time: 0 m 51 s]\n",
            "[Epoch 52][Train on 403 [MSE: 0.0019  PSNR: 27.1997]][Val on 50 [MSE: 0.0016  PSNR: 27.8542]][Time: 0 m 51 s]\n",
            "[Epoch 53][Train on 403 [MSE: 0.0019  PSNR: 27.2678]][Val on 50 [MSE: 0.0016  PSNR: 27.8933]][Time: 0 m 51 s]\n",
            "[Epoch 54][Train on 403 [MSE: 0.0019  PSNR: 27.3040]][Val on 50 [MSE: 0.0016  PSNR: 27.9485]][Time: 0 m 51 s]\n",
            "[Epoch 55][Train on 403 [MSE: 0.0019  PSNR: 27.3230]][Val on 50 [MSE: 0.0016  PSNR: 27.9413]][Time: 0 m 51 s]\n",
            "[Epoch 56][Train on 403 [MSE: 0.0018  PSNR: 27.3295]][Val on 50 [MSE: 0.0025  PSNR: 26.0726]][Time: 0 m 50 s]\n",
            "[Epoch 57][Train on 403 [MSE: 0.0018  PSNR: 27.3557]][Val on 50 [MSE: 0.0017  PSNR: 27.8124]][Time: 0 m 51 s]\n",
            "[Epoch 58][Train on 403 [MSE: 0.0018  PSNR: 27.3703]][Val on 50 [MSE: 0.0048  PSNR: 23.1810]][Time: 0 m 51 s]\n",
            "[Epoch 59][Train on 403 [MSE: 0.0020  PSNR: 27.0911]][Val on 50 [MSE: 0.0017  PSNR: 27.6629]][Time: 0 m 50 s]\n",
            "[Epoch 0][Train on 403 [MSE: 0.0019  PSNR: 27.2973]][Val on 50 [MSE: 0.0016  PSNR: 28.0244]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0018  PSNR: 27.4756]][Val on 50 [MSE: 0.0016  PSNR: 27.9995]][Time: 0 m 51 s]\n",
            "[Epoch 2][Train on 403 [MSE: 0.0017  PSNR: 27.5757]][Val on 50 [MSE: 0.0015  PSNR: 28.1350]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0017  PSNR: 27.6421]][Val on 50 [MSE: 0.0015  PSNR: 28.1564]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0017  PSNR: 27.6857]][Val on 50 [MSE: 0.0015  PSNR: 28.1987]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0017  PSNR: 27.7488]][Val on 50 [MSE: 0.0015  PSNR: 28.2750]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0016  PSNR: 27.8289]][Val on 50 [MSE: 0.0015  PSNR: 28.3544]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0016  PSNR: 27.9102]][Val on 50 [MSE: 0.0014  PSNR: 28.4427]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0016  PSNR: 27.9929]][Val on 50 [MSE: 0.0014  PSNR: 28.4902]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0016  PSNR: 28.0567]][Val on 50 [MSE: 0.0014  PSNR: 28.5784]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 10][Train on 403 [MSE: 0.0015  PSNR: 28.1816]][Val on 50 [MSE: 0.0013  PSNR: 28.7102]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0015  PSNR: 28.3029]][Val on 50 [MSE: 0.0013  PSNR: 28.8036]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0014  PSNR: 28.3932]][Val on 50 [MSE: 0.0013  PSNR: 28.8790]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0015  PSNR: 28.3700]][Val on 50 [MSE: 0.0014  PSNR: 28.6451]][Time: 0 m 51 s]\n",
            "[Epoch 14][Train on 403 [MSE: 0.0014  PSNR: 28.5262]][Val on 50 [MSE: 0.0012  PSNR: 29.0616]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 15][Train on 403 [MSE: 0.0013  PSNR: 28.7683]][Val on 50 [MSE: 0.0012  PSNR: 29.2352]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0013  PSNR: 28.9502]][Val on 50 [MSE: 0.0012  PSNR: 29.3673]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0012  PSNR: 29.0783]][Val on 50 [MSE: 0.0011  PSNR: 29.4280]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0012  PSNR: 29.1937]][Val on 50 [MSE: 0.0011  PSNR: 29.4456]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0012  PSNR: 29.2766]][Val on 50 [MSE: 0.0011  PSNR: 29.5431]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 20][Train on 403 [MSE: 0.0012  PSNR: 29.3425]][Val on 50 [MSE: 0.0011  PSNR: 29.5682]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 21][Train on 403 [MSE: 0.0011  PSNR: 29.3987]][Val on 50 [MSE: 0.0011  PSNR: 29.6089]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 22][Train on 403 [MSE: 0.0011  PSNR: 29.4482]][Val on 50 [MSE: 0.0011  PSNR: 29.6511]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 23][Train on 403 [MSE: 0.0011  PSNR: 29.4930]][Val on 50 [MSE: 0.0011  PSNR: 29.6912]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 24][Train on 403 [MSE: 0.0011  PSNR: 29.5336]][Val on 50 [MSE: 0.0011  PSNR: 29.7293]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 25][Train on 403 [MSE: 0.0011  PSNR: 29.5704]][Val on 50 [MSE: 0.0011  PSNR: 29.7572]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 26][Train on 403 [MSE: 0.0011  PSNR: 29.6062]][Val on 50 [MSE: 0.0011  PSNR: 29.7773]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 27][Train on 403 [MSE: 0.0011  PSNR: 29.6398]][Val on 50 [MSE: 0.0010  PSNR: 29.8005]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 28][Train on 403 [MSE: 0.0011  PSNR: 29.6709]][Val on 50 [MSE: 0.0010  PSNR: 29.8072]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 29][Train on 403 [MSE: 0.0011  PSNR: 29.6992]][Val on 50 [MSE: 0.0010  PSNR: 29.8362]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 30][Train on 403 [MSE: 0.0011  PSNR: 29.7285]][Val on 50 [MSE: 0.0010  PSNR: 29.8350]][Time: 0 m 51 s]\n",
            "[Epoch 31][Train on 403 [MSE: 0.0011  PSNR: 29.7559]][Val on 50 [MSE: 0.0010  PSNR: 29.8547]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 32][Train on 403 [MSE: 0.0011  PSNR: 29.7845]][Val on 50 [MSE: 0.0010  PSNR: 29.8733]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 33][Train on 403 [MSE: 0.0010  PSNR: 29.8115]][Val on 50 [MSE: 0.0010  PSNR: 29.8747]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 34][Train on 403 [MSE: 0.0010  PSNR: 29.8357]][Val on 50 [MSE: 0.0010  PSNR: 29.8913]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 35][Train on 403 [MSE: 0.0010  PSNR: 29.8591]][Val on 50 [MSE: 0.0010  PSNR: 29.9061]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 36][Train on 403 [MSE: 0.0010  PSNR: 29.8806]][Val on 50 [MSE: 0.0010  PSNR: 29.9273]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 37][Train on 403 [MSE: 0.0010  PSNR: 29.8987]][Val on 50 [MSE: 0.0010  PSNR: 29.9493]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 38][Train on 403 [MSE: 0.0010  PSNR: 29.9173]][Val on 50 [MSE: 0.0010  PSNR: 29.9563]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 39][Train on 403 [MSE: 0.0010  PSNR: 29.9380]][Val on 50 [MSE: 0.0010  PSNR: 29.9761]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 40][Train on 403 [MSE: 0.0010  PSNR: 29.9584]][Val on 50 [MSE: 0.0010  PSNR: 29.9905]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 41][Train on 403 [MSE: 0.0010  PSNR: 29.9797]][Val on 50 [MSE: 0.0010  PSNR: 29.9978]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 42][Train on 403 [MSE: 0.0010  PSNR: 29.9975]][Val on 50 [MSE: 0.0010  PSNR: 30.0042]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 43][Train on 403 [MSE: 0.0010  PSNR: 30.0162]][Val on 50 [MSE: 0.0010  PSNR: 30.0234]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 44][Train on 403 [MSE: 0.0010  PSNR: 30.0330]][Val on 50 [MSE: 0.0010  PSNR: 30.0359]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 45][Train on 403 [MSE: 0.0010  PSNR: 30.0491]][Val on 50 [MSE: 0.0010  PSNR: 30.0630]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 46][Train on 403 [MSE: 0.0010  PSNR: 30.0678]][Val on 50 [MSE: 0.0010  PSNR: 30.0732]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 47][Train on 403 [MSE: 0.0010  PSNR: 30.0853]][Val on 50 [MSE: 0.0010  PSNR: 30.0876]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 48][Train on 403 [MSE: 0.0010  PSNR: 30.1067]][Val on 50 [MSE: 0.0010  PSNR: 30.0963]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 49][Train on 403 [MSE: 0.0010  PSNR: 30.1272]][Val on 50 [MSE: 0.0010  PSNR: 30.0904]][Time: 0 m 51 s]\n",
            "[Epoch 50][Train on 403 [MSE: 0.0010  PSNR: 30.1469]][Val on 50 [MSE: 0.0010  PSNR: 30.0825]][Time: 0 m 51 s]\n",
            "[Epoch 51][Train on 403 [MSE: 0.0010  PSNR: 30.1654]][Val on 50 [MSE: 0.0010  PSNR: 30.0931]][Time: 0 m 51 s]\n",
            "[Epoch 52][Train on 403 [MSE: 0.0010  PSNR: 30.1823]][Val on 50 [MSE: 0.0010  PSNR: 30.0973]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 53][Train on 403 [MSE: 0.0010  PSNR: 30.1998]][Val on 50 [MSE: 0.0010  PSNR: 30.1101]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 54][Train on 403 [MSE: 0.0010  PSNR: 30.2152]][Val on 50 [MSE: 0.0010  PSNR: 30.1308]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 55][Train on 403 [MSE: 0.0009  PSNR: 30.2282]][Val on 50 [MSE: 0.0010  PSNR: 30.1574]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 56][Train on 403 [MSE: 0.0009  PSNR: 30.2427]][Val on 50 [MSE: 0.0010  PSNR: 30.1752]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 57][Train on 403 [MSE: 0.0009  PSNR: 30.2561]][Val on 50 [MSE: 0.0010  PSNR: 30.2010]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 58][Train on 403 [MSE: 0.0009  PSNR: 30.2689]][Val on 50 [MSE: 0.0010  PSNR: 30.2211]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 59][Train on 403 [MSE: 0.0009  PSNR: 30.2827]][Val on 50 [MSE: 0.0009  PSNR: 30.2406]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "------Best Combination saved [Epoch: 60 - Learning Rate: 0.001]-------\n",
            "[Epoch 0][Train on 403 [MSE: 0.0009  PSNR: 30.3763]][Val on 50 [MSE: 0.0009  PSNR: 30.4440]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 1][Train on 403 [MSE: 0.0009  PSNR: 30.3988]][Val on 50 [MSE: 0.0009  PSNR: 30.4534]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 2][Train on 403 [MSE: 0.0009  PSNR: 30.4031]][Val on 50 [MSE: 0.0009  PSNR: 30.4577]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 3][Train on 403 [MSE: 0.0009  PSNR: 30.4070]][Val on 50 [MSE: 0.0009  PSNR: 30.4615]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 4][Train on 403 [MSE: 0.0009  PSNR: 30.4106]][Val on 50 [MSE: 0.0009  PSNR: 30.4647]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 5][Train on 403 [MSE: 0.0009  PSNR: 30.4140]][Val on 50 [MSE: 0.0009  PSNR: 30.4688]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 6][Train on 403 [MSE: 0.0009  PSNR: 30.4172]][Val on 50 [MSE: 0.0009  PSNR: 30.4722]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 7][Train on 403 [MSE: 0.0009  PSNR: 30.4203]][Val on 50 [MSE: 0.0009  PSNR: 30.4750]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 8][Train on 403 [MSE: 0.0009  PSNR: 30.4234]][Val on 50 [MSE: 0.0009  PSNR: 30.4781]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 9][Train on 403 [MSE: 0.0009  PSNR: 30.4264]][Val on 50 [MSE: 0.0009  PSNR: 30.4806]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 10][Train on 403 [MSE: 0.0009  PSNR: 30.4294]][Val on 50 [MSE: 0.0009  PSNR: 30.4830]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 11][Train on 403 [MSE: 0.0009  PSNR: 30.4323]][Val on 50 [MSE: 0.0009  PSNR: 30.4858]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 12][Train on 403 [MSE: 0.0009  PSNR: 30.4352]][Val on 50 [MSE: 0.0009  PSNR: 30.4888]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 13][Train on 403 [MSE: 0.0009  PSNR: 30.4380]][Val on 50 [MSE: 0.0009  PSNR: 30.4915]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 14][Train on 403 [MSE: 0.0009  PSNR: 30.4408]][Val on 50 [MSE: 0.0009  PSNR: 30.4941]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 15][Train on 403 [MSE: 0.0009  PSNR: 30.4436]][Val on 50 [MSE: 0.0009  PSNR: 30.4967]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 16][Train on 403 [MSE: 0.0009  PSNR: 30.4464]][Val on 50 [MSE: 0.0009  PSNR: 30.4992]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 17][Train on 403 [MSE: 0.0009  PSNR: 30.4491]][Val on 50 [MSE: 0.0009  PSNR: 30.5018]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 18][Train on 403 [MSE: 0.0009  PSNR: 30.4517]][Val on 50 [MSE: 0.0009  PSNR: 30.5045]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 19][Train on 403 [MSE: 0.0009  PSNR: 30.4544]][Val on 50 [MSE: 0.0009  PSNR: 30.5069]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 20][Train on 403 [MSE: 0.0009  PSNR: 30.4571]][Val on 50 [MSE: 0.0009  PSNR: 30.5095]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 21][Train on 403 [MSE: 0.0009  PSNR: 30.4597]][Val on 50 [MSE: 0.0009  PSNR: 30.5116]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 22][Train on 403 [MSE: 0.0009  PSNR: 30.4623]][Val on 50 [MSE: 0.0009  PSNR: 30.5140]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 23][Train on 403 [MSE: 0.0009  PSNR: 30.4650]][Val on 50 [MSE: 0.0009  PSNR: 30.5166]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 24][Train on 403 [MSE: 0.0009  PSNR: 30.4675]][Val on 50 [MSE: 0.0009  PSNR: 30.5187]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 25][Train on 403 [MSE: 0.0009  PSNR: 30.4701]][Val on 50 [MSE: 0.0009  PSNR: 30.5210]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 26][Train on 403 [MSE: 0.0009  PSNR: 30.4727]][Val on 50 [MSE: 0.0009  PSNR: 30.5234]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 27][Train on 403 [MSE: 0.0009  PSNR: 30.4752]][Val on 50 [MSE: 0.0009  PSNR: 30.5256]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 28][Train on 403 [MSE: 0.0009  PSNR: 30.4778]][Val on 50 [MSE: 0.0009  PSNR: 30.5275]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 29][Train on 403 [MSE: 0.0009  PSNR: 30.4804]][Val on 50 [MSE: 0.0009  PSNR: 30.5300]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 30][Train on 403 [MSE: 0.0009  PSNR: 30.4829]][Val on 50 [MSE: 0.0009  PSNR: 30.5322]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 31][Train on 403 [MSE: 0.0009  PSNR: 30.4854]][Val on 50 [MSE: 0.0009  PSNR: 30.5346]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 32][Train on 403 [MSE: 0.0009  PSNR: 30.4879]][Val on 50 [MSE: 0.0009  PSNR: 30.5368]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 33][Train on 403 [MSE: 0.0009  PSNR: 30.4904]][Val on 50 [MSE: 0.0009  PSNR: 30.5388]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 34][Train on 403 [MSE: 0.0009  PSNR: 30.4929]][Val on 50 [MSE: 0.0009  PSNR: 30.5412]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 35][Train on 403 [MSE: 0.0009  PSNR: 30.4953]][Val on 50 [MSE: 0.0009  PSNR: 30.5432]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 36][Train on 403 [MSE: 0.0009  PSNR: 30.4977]][Val on 50 [MSE: 0.0009  PSNR: 30.5453]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 37][Train on 403 [MSE: 0.0009  PSNR: 30.5001]][Val on 50 [MSE: 0.0009  PSNR: 30.5474]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 38][Train on 403 [MSE: 0.0009  PSNR: 30.5025]][Val on 50 [MSE: 0.0009  PSNR: 30.5491]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 39][Train on 403 [MSE: 0.0009  PSNR: 30.5049]][Val on 50 [MSE: 0.0009  PSNR: 30.5509]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 40][Train on 403 [MSE: 0.0009  PSNR: 30.5073]][Val on 50 [MSE: 0.0009  PSNR: 30.5534]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 41][Train on 403 [MSE: 0.0009  PSNR: 30.5097]][Val on 50 [MSE: 0.0009  PSNR: 30.5554]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 42][Train on 403 [MSE: 0.0009  PSNR: 30.5121]][Val on 50 [MSE: 0.0009  PSNR: 30.5575]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 43][Train on 403 [MSE: 0.0009  PSNR: 30.5145]][Val on 50 [MSE: 0.0009  PSNR: 30.5597]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 44][Train on 403 [MSE: 0.0009  PSNR: 30.5168]][Val on 50 [MSE: 0.0009  PSNR: 30.5619]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 45][Train on 403 [MSE: 0.0009  PSNR: 30.5192]][Val on 50 [MSE: 0.0009  PSNR: 30.5641]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 46][Train on 403 [MSE: 0.0009  PSNR: 30.5216]][Val on 50 [MSE: 0.0009  PSNR: 30.5662]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 47][Train on 403 [MSE: 0.0009  PSNR: 30.5240]][Val on 50 [MSE: 0.0009  PSNR: 30.5682]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 48][Train on 403 [MSE: 0.0009  PSNR: 30.5263]][Val on 50 [MSE: 0.0009  PSNR: 30.5705]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 49][Train on 403 [MSE: 0.0009  PSNR: 30.5286]][Val on 50 [MSE: 0.0009  PSNR: 30.5724]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 50][Train on 403 [MSE: 0.0009  PSNR: 30.5310]][Val on 50 [MSE: 0.0009  PSNR: 30.5743]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 51][Train on 403 [MSE: 0.0009  PSNR: 30.5334]][Val on 50 [MSE: 0.0009  PSNR: 30.5767]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 52][Train on 403 [MSE: 0.0009  PSNR: 30.5357]][Val on 50 [MSE: 0.0009  PSNR: 30.5787]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 53][Train on 403 [MSE: 0.0009  PSNR: 30.5381]][Val on 50 [MSE: 0.0009  PSNR: 30.5811]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 54][Train on 403 [MSE: 0.0009  PSNR: 30.5404]][Val on 50 [MSE: 0.0009  PSNR: 30.5831]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 55][Train on 403 [MSE: 0.0009  PSNR: 30.5428]][Val on 50 [MSE: 0.0009  PSNR: 30.5851]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 56][Train on 403 [MSE: 0.0009  PSNR: 30.5451]][Val on 50 [MSE: 0.0009  PSNR: 30.5869]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 57][Train on 403 [MSE: 0.0009  PSNR: 30.5474]][Val on 50 [MSE: 0.0009  PSNR: 30.5888]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 58][Train on 403 [MSE: 0.0009  PSNR: 30.5497]][Val on 50 [MSE: 0.0009  PSNR: 30.5908]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "[Epoch 59][Train on 403 [MSE: 0.0009  PSNR: 30.5520]][Val on 50 [MSE: 0.0009  PSNR: 30.5930]][Time: 0 m 51 s]\n",
            "-------Saving best weights-------\n",
            "-------Best weights saved-------\n",
            "------Best Combination saved [Epoch: 60 - Learning Rate: 0.0001]-------\n",
            "Best MSE: 0.0008723719720728695\n",
            "Best PSNR: 30.59298324584961\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for numEpoch in epochList:\n",
        "    for lr in learningRateList:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        bestMse = 9000000000000000000.0             # Miglior MSE della singola combinazione\n",
        "        bestPsnr = -900000000000000000.0            # Miglior PSNR della singola combinazione\n",
        "\n",
        "        bestMSES, bestPSNRS, MSETrainList, MSEValList, PSNRTrainList, PSNRValList = training (trainDataload, trainDataloadRic, valDataload, valDataloadRic, numEpoch, model, criterion, optimizer, bestMse, bestPsnr, weightPath)\n",
        "\n",
        "        # Aggiorno i valori di miglior MSE\n",
        "        if bestMSES < bestMSEComb:\n",
        "            bestMSEComb = bestMSES\n",
        "            bestPSNRComb = bestPSNRS\n",
        "            # Caricamento dei pesi\n",
        "            torch.save(model.cpu().state_dict(), weightPathComb)\n",
        "            print(f\"------Best Combination saved [Epoch: {numEpoch} - Learning Rate: {lr}]-------\")\n",
        "            model.cuda()\n",
        "\n",
        "        # Visualizzazione grafico prestazioni (disabilitato per non intasare l'output)\n",
        "        #graphVisualization(MSETrainList, MSEValList, PSNRTrainList, PSNRValList)\n",
        "\n",
        "print(f\"Best MSE: {bestMSEComb}\")\n",
        "print(f\"Best PSNR: {bestPSNRComb}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc8e01c",
      "metadata": {
        "id": "3dc8e01c",
        "outputId": "2f946f8f-6a6a-47d0-853b-4650670a4c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Test] [MSE: 0.0008  PSNR: 30.8902] [Time: 0 m 2 s]\n"
          ]
        }
      ],
      "source": [
        "# Percorsi output\n",
        "outputInPath = \"outputs/SuperResolution/testSet/\"\n",
        "outputTruthPath = \"outputs/SuperResolution/groundTruth/\"\n",
        "outputOutPath = \"outputs/SuperResolution/results/\"\n",
        "os.makedirs(outputInPath, exist_ok=True)\n",
        "os.makedirs(outputTruthPath, exist_ok=True)\n",
        "os.makedirs(outputOutPath, exist_ok=True)\n",
        "\n",
        "# Testing\n",
        "outputsTest = testing(testDataload, testDataloadRic, model, criterion, weightPathComb)\n",
        "\n",
        "# Iterazione sia su outputsTest che su testDataloadRic\n",
        "index = 1\n",
        "testIter = iter(testDataloadRic)  \n",
        "truthIter = iter(testDataload)\n",
        "\n",
        "# Salvataggio locale delle immagini \n",
        "for batchOut in outputsTest:\n",
        "    batchIn = next(testIter)        # Ottienimento del batch originale\n",
        "    batchTruth = next(truthIter)\n",
        "\n",
        "    for j in range(batchOut.size(0)):\n",
        "        # --- Output ---\n",
        "        imgOut = batchOut[j].detach().cpu().clamp(0, 1)\n",
        "        imgOut = imgOut.permute(1, 2, 0).numpy()\n",
        "        pathOut = os.path.join(outputOutPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathOut, imgOut)\n",
        "        # --- Input ---\n",
        "        imgIn = batchIn[j].detach().cpu().clamp(0, 1)\n",
        "        imgIn = imgIn.permute(1, 2, 0).numpy()\n",
        "        pathIn = os.path.join(outputInPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathIn, imgIn)\n",
        "        # --- Ground Truth ---\n",
        "        imgTruth = batchTruth[j].detach().cpu().clamp(0, 1)\n",
        "        imgTruth = imgTruth.permute(1, 2, 0).numpy()\n",
        "        pathTruth = os.path.join(outputTruthPath, f\"image_{index}.jpg\")\n",
        "        plt.imsave(pathTruth, imgTruth)\n",
        "        index += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
